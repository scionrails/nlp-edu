{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "참고 코드 : https://wikidocs.net/45101"
      ],
      "metadata": {
        "id": "mAnjSitG23E4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZeT0j_fx1M6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
      ],
      "metadata": {
        "id": "Nq6PBYK816AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlxjq_sX19TA",
        "outputId": "089fcbbf-beb2-4de0-b6e1-146c3a49fdbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 1346\n",
            "{'있었다': 1, '소년은': 2, '소녀가': 3, '한': 4, '소녀의': 5, '있는': 6, '그러나': 7, '소녀는': 8, '소년이': 9, '했다': 10, '않았다': 11, '가': 12, '있다': 13, '앉아': 14, '안고': 15, '더': 16, '소년의': 17, '전에': 18, '그': 19, '걸': 20, '수': 21, '좀': 22, '뵈지': 23, '하는': 24, '같은': 25, '손을': 26, '하고': 27, '개울가로': 28, '나왔다': 29, '이': 30, '그리고는': 31, '가을': 32, '것이었다': 33, '없이': 34, '것': 35, '번': 36, '이게': 37, '”소녀가': 38, '”소년은': 39, '윤': 40, '그런데': 41, '개울': 42, '다음': 43, '그냥': 44, '그대로': 45, '그러다가': 46, '바보': 47, '저도': 48, '모르게': 49, '소녀': 50, '같았다': 51, '날': 52, '얼굴이': 53, '몇': 54, '시작했다': 55, '소리가': 56, '무슨': 57, '저': 58, '못': 59, '꽃을': 60, '우리': 61, '많이': 62, '게': 63, '그날': 64, '호두': 65, '소녀를': 66, '물장난을': 67, '것이다': 68, '서울': 69, '이런': 70, '듯이': 71, '며칠째': 72, '학교에서': 73, '돌아오는': 74, '오늘은': 75, '징검다리': 76, '뚝에': 77, '길을': 78, '날은': 79, '세수를': 80, '분홍': 81, '스웨터': 82, '이번에는': 83, '낸다': 84, '자꾸': 85, '하나': 86, '일어나': 87, '징검다리를': 88, '뛰어': 89, '다': 90, '생각됐다': 91, '않는다': 92, '갈꽃이': 93, '것만': 94, '서': 95, '조약돌을': 96, '주머니': 97, '속': 98, '보았다': 99, '두': 100, '달렸다': 101, '체': 102, '참': 103, '왔다': 104, '허수아비가': 105, '집으로': 106, '생각이': 107, '또': 108, '달려간다': 109, '한다는': 110, '와': 111, '저놈의': 112, '지금': 113, '자기가': 114, '참외': 115, '”“그럼': 116, '”소년이': 117, '들어': 118, '소녀에게': 119, '향해': 120, '꽃': 121, '다시': 122, '골라': 123, '것도': 124, '큰': 125, '등을': 126, '같다': 127, '그저': 128, '비를': 129, '없었다': 130, '수숫단': 131, '속을': 132, '물이': 133, '소녀네가': 134, '초시': 135, '이사': 136, '말을': 137, '아버지가': 138, '보자': 139, '곧': 140, '알': 141, '보지': 142, '벌써': 143, '길에': 144, '한가운데': 145, '버렸다': 146, '지나가는': 147, '사람이': 148, '있어': 149, '주었다': 150, '늦게': 151, '걷어올린': 152, '목덜미가': 153, '물속을': 154, '갑자기': 155, '움켜': 156, '물만': 157, '무엇을': 158, '집어': 159, '벌떡': 160, '홱': 161, '이리로': 162, '달린다': 163, '사잇길로': 164, '들어섰다': 165, '아래': 166, '꽤': 167, '시간이': 168, '지났다고': 169, '그러고도': 170, '갈꽃을': 171, '그리고': 172, '아주': 173, '그림자가': 174, '잡는': 175, '물속에': 176, '손으로': 177, '움키었다': 178, '놀라': 179, '있지': 180, '내가': 181, '’': 182, '이쪽': 183, '길에는': 184, '냄새가': 185, '‘바보': 186, '개울가에': 187, '뿐': 188, '“얘': 189, '눈을': 190, '한다': 191, '산': 192, '곁을': 193, '지났다': 194, '일찍': 195, '돌아가': 196, '살포시': 197, '그리로': 198, '오늘': 199, '생각을': 200, '얼굴에': 201, '쪽빛으로': 202, '하늘이': 203, '맴을': 204, '어지럽다': 205, '독수리': 206, '온': 207, '곳에': 208, '먼저': 209, '수숫단을': 210, '세워': 211, '놓은': 212, '아직': 213, '덜': 214, '건넨다': 215, '이렇게': 216, '만다': 217, '“참': 218, '눈에': 219, '산을': 220, '달려갔다': 221, '……': 222, '난': 223, '꽃이': 224, '해': 225, '보조개를': 226, '떠올리며': 227, '올라갔다': 228, '주위가': 229, '비탈진': 230, '밑에서': 231, '난다': 232, '달린': 233, '줄기를': 234, '잡아': 235, '가지고': 236, '송아지가': 237, '그리': 238, '고삐를': 239, '흰': 240, '꽃묶음': 241, '자기': 242, '할': 243, '올라왔다': 244, '송아지': 245, '등에서': 246, '어린': 247, '굵은': 248, '보였다': 249, '그을': 250, '비가': 251, '어깨를': 252, '벗어': 253, '비에': 254, '젖은': 255, '송이를': 256, '비집어': 257, '안': 258, '됐다': 259, '들어와': 260, '앉으라고': 261, '몸': 262, '확': 263, '고개를': 264, '언제': 265, '몰래': 266, '만지작거리며': 267, '가만히': 268, '느꼈다': 269, '갈림길에서': 270, '제사': 271, '나서': 272, '어른들의': 273, '집마저': 274, '남의': 275, '손에': 276, '가는': 277, '간다는': 278, '수없이': 279, '밤': 280, '떡쇠': 281, '할아버지네': 282, '갔다': 283, '봐': 284, '두었던': 285, '작대기를': 286, '떨어져라': 287, '건': 288, '어디': 289, '가시느냐고': 290, '아버지는': 291, '될까': 292, '서당골': 293, '말이': 294, '내일': 295, '있던': 296, '계집애': 297, '애': 298, '이번': 299, '않아': 300, '개울가에서': 301, '초시네': 302, '증손녀': 303, '曾孫女': 304, '딸이라는': 305, '개울에다': 306, '잠그고': 307, '서는': 308, '개울물을': 309, '못하기나': 310, '물장난이었다': 311, '어제까지': 312, '기슭에서': 313, '하더니': 314, '앉아서': 315, '비키기를': 316, '기다리자는': 317, '요행': 318, '비켜': 319, '소매를': 320, '마냥': 321, '희었다': 322, '한참': 323, '나더니': 324, '빤히': 325, '들여다본다': 326, '얼굴이라도': 327, '비추어': 328, '보는': 329, '것이리라': 330, '물을': 331, '고기': 332, '새끼라도': 333, '듯': 334, '아는지': 335, '모르는지': 336, '날쌔게': 337, '번번이': 338, '허탕이다': 339, '재미있는': 340, '양': 341, '움킨다': 342, '어제처럼': 343, '개울을': 344, '건너는': 345, '있어야': 346, '비킬': 347, '모양이다': 348, '물속에서': 349, '하얀': 350, '조약돌이었다': 351, '팔짝팔짝': 352, '건너간다': 353, '건너가더니만': 354, '돌아서며': 355, '“이': 356, '”조약돌이': 357, '날아왔다': 358, '일어섰다': 359, '단발머리를': 360, '나풀거리며': 361, '막': 362, '갈밭': 363, '뒤에는': 364, '청량한': 365, '햇살': 366, '빛나는': 367, '갈꽃뿐': 368, '이제': 369, '저쯤': 370, '갈밭머리로': 371, '나타나리라': 372, '오랜': 373, '그런데도': 374, '나타나지': 375, '발돋움을': 376, '상당한': 377, '저쪽': 378, '갈밭머리에': 379, '옴큼': 380, '움직였다': 381, '이제는': 382, '천천한': 383, '걸음이었다': 384, '유난히': 385, '맑은': 386, '햇살이': 387, '갈꽃': 388, '머리에서': 389, '반짝거렸다': 390, '아닌': 391, '들길을': 392, '걸어가는': 393, '않게': 394, '되기까지': 395, '문득': 396, '가던지': 397, '내려다보았다': 398, '물기가': 399, '걷혀': 400, '주머니에': 401, '넣었다': 402, '날부터': 403, '다행이었다': 404, '이상한': 405, '일이었다': 406, '않는': 407, '날이': 408, '계속될수록': 409, '가슴': 410, '한구석에는': 411, '어딘가': 412, '허전함이': 413, '자리': 414, '주무르는': 415, '버릇이': 416, '생겼다': 417, '그러한': 418, '어떤': 419, '하던': 420, '한가운데에': 421, '잠갔다': 422, '하였다': 423, '들여다보았다': 424, '검게': 425, '탄': 426, '비치었다': 427, '싫었다': 428, '물속의': 429, '얼굴을': 430, '번이고': 431, '깜짝': 432, '일어나고': 433, '말았다': 434, '건너오고': 435, '않느냐': 436, '‘숨어서': 437, '일을': 438, '엿보고': 439, '있었구나': 440, '달리기를': 441, '디딤돌을': 442, '헛디뎠다': 443, '발이': 444, '빠졌다': 445, '몸을': 446, '가릴': 447, '데가': 448, '줬으면': 449, '좋겠다': 450, '갈밭도': 451, '없다': 452, '메밀': 453, '밭이다': 454, '메밀꽃': 455, '짜릿하게': 456, '코를': 457, '찌른다고': 458, '미간이': 459, '아찔했다': 460, '찝찔한': 461, '액체가': 462, '입술에': 463, '흘러들었다': 464, '코피였다': 465, '코피를': 466, '훔쳐내면서': 467, '어디선가': 468, '바보’': 469, '자꾸만': 470, '뒤따라오는': 471, '토요일이었다': 472, '이르니': 473, '보이지': 474, '않던': 475, '건너편': 476, '가에': 477, '모르는': 478, '건너기': 479, '얼마': 480, '앞에서': 481, '실수를': 482, '했을': 483, '여태': 484, '큰길': 485, '가듯이': 486, '건너던': 487, '조심스럽게': 488, '건넌다': 489, '”못': 490, '들은': 491, '체했다': 492, '둑': 493, '위로': 494, '올라섰다': 495, '조': 496, '개지': 497, '”자기도': 498, '돌아섰다': 499, '맑고': 500, '검은': 501, '눈과': 502, '마주쳤다': 503, '얼른': 504, '손바닥으로': 505, '떨구었다': 506, '“비단': 507, '조개': 508, '”“이름도': 509, '곱다': 510, '”갈림길에': 511, '여기서': 512, '아래편으로': 513, '삼': 514, '마장쯤': 515, '우대로': 516, '십': 517, '리': 518, '가까운': 519, '가야': 520, '걸음을': 521, '멈추며': 522, '“너': 523, '너머에': 524, '본': 525, '일': 526, '있니': 527, '”벌': 528, '끝을': 529, '가리켰다': 530, '“없다': 531, '”“우리': 532, '않으련': 533, '시골': 534, '오니까': 535, '혼자서': 536, '심심해': 537, '견디겠다': 538, '”“저래': 539, '봬도': 540, '멀다': 541, '”“멀면': 542, '얼마나': 543, '멀기에': 544, '있을': 545, '땐': 546, '사뭇': 547, '먼': 548, '데까지': 549, '소풍': 550, '갔었다': 551, '”소녀의': 552, '눈이': 553, '금세': 554, '’할': 555, '논': 556, '벼': 557, '가을걷이는': 558, '새끼줄을': 559, '흔들었다': 560, '참새가': 561, '마리': 562, '날아간다': 563, '‘참': 564, '텃논의': 565, '참새를': 566, '봐야': 567, '할걸': 568, '든다': 569, '“야': 570, '재밌다': 571, '허수아비': 572, '줄을': 573, '잡더니': 574, '흔들어': 575, '댄다': 576, '우쭐거리며': 577, '춤을': 578, '춘다': 579, '왼쪽': 580, '볼에': 581, '보조개가': 582, '패었다': 583, '저만큼': 584, '뒤를': 585, '소년도': 586, '집안일을': 587, '도와야': 588, '잊어버리기라도': 589, '하려는': 590, '스쳐': 591, '메뚜기가': 592, '따끔따끔': 593, '부딪친다': 594, '한껏': 595, '갠': 596, '눈앞에서': 597, '돈다': 598, '독수리가': 599, '돌고': 600, '있기': 601, '때문이다': 602, '돌아다보니': 603, '지나쳐': 604, '허수아비를': 605, '흔들고': 606, '전': 607, '허수아비보다': 608, '우쭐거린다': 609, '논이': 610, '끝난': 611, '도랑이': 612, '건넜다': 613, '거기서부터': 614, '밑까지는': 615, '밭이었다': 616, '밭머리를': 617, '“저게': 618, '뭐니': 619, '”“원두막': 620, '”“여기': 621, '맛있니': 622, '맛도': 623, '좋지만': 624, '수박': 625, '맛은': 626, '좋다': 627, '”“하나': 628, '먹어': 629, '봤으면': 630, '그루에': 631, '심은': 632, '무밭으로': 633, '들어가': 634, '무': 635, '밑을': 636, '뽑아': 637, '밑이': 638, '잎을': 639, '비틀어': 640, '팽개친': 641, '후': 642, '개': 643, '먹어야': 644, '대강이를': 645, '입': 646, '베물어': 647, '낸': 648, '손톱으로': 649, '돌이': 650, '껍질을': 651, '벗겨': 652, '우쩍': 653, '깨문다': 654, '소녀도': 655, '따라': 656, '세': 657, '입도': 658, '먹고': 659, '“아': 660, '맵고': 661, '지려': 662, '”하며': 663, '집어던지고': 664, '맛없어': 665, '먹겠다': 666, '멀리': 667, '팽개쳐': 668, '산이': 669, '가까워졌다': 670, '단풍이': 671, '따가웠다': 672, '“야아': 673, '이번은': 674, '뒤따라': 675, '달리지': 676, '소녀보다': 677, '많은': 678, '꺾었다': 679, '“이게': 680, '들국화': 681, '싸리꽃': 682, '도라지꽃': 683, '”“도라지꽃이': 684, '예쁜': 685, '줄은': 686, '몰랐네': 687, '보랏빛이': 688, '좋아': 689, '양산같이': 690, '생긴': 691, '노란': 692, '뭐지': 693, '”“마타리': 694, '”소녀는': 695, '마타리': 696, '양산': 697, '받듯이': 698, '보인다': 699, '약간': 700, '상기된': 701, '옴큼을': 702, '꺾어': 703, '싱싱한': 704, '꽃가지만': 705, '소녀는“하나도': 706, '버리지': 707, '마라': 708, '”산마루께로': 709, '맞은편': 710, '골짜기에': 711, '오순도순': 712, '초가집이': 713, '모여': 714, '누가': 715, '말할': 716, '아닌데': 717, '바위에': 718, '나란히': 719, '걸터앉았다': 720, '유달리': 721, '조용해진': 722, '따가운': 723, '햇살만이': 724, '말라가는': 725, '풀': 726, '냄새를': 727, '퍼뜨리고': 728, '“저건': 729, '꽃이지': 730, '”적잖이': 731, '칡덩굴이': 732, '엉키어': 733, '달고': 734, '“꼭': 735, '등꽃': 736, '같네': 737, '학교에': 738, '등나무가': 739, '있었단다': 740, '보니까': 741, '등나무': 742, '놀던': 743, '동무들': 744, '조용히': 745, '곳으로': 746, '간다': 747, '꽃송이가': 748, '잡고': 749, '끊기': 750, '시작한다': 751, '좀처럼': 752, '끊어지지': 753, '안간힘을': 754, '쓰다가': 755, '그만': 756, '미끄러지고': 757, '칡덩굴을': 758, '그러쥐었다': 759, '내밀었다': 760, '이끌어': 761, '올리며': 762, '제가': 763, '꺾어다': 764, '줄': 765, '것을': 766, '잘못했다고': 767, '뉘우친다': 768, '오른쪽': 769, '무릎에': 770, '핏방울이': 771, '내맺혔다': 772, '생채기에': 773, '입술을': 774, '가져다': 775, '대고': 776, '빨기': 777, '했는지': 778, '저쪽으로': 779, '만에': 780, '숨이': 781, '차': 782, '돌아온': 783, '소년은“이걸': 784, '바르면': 785, '낫는다': 786, '”송진을': 787, '생채기에다': 788, '문질러': 789, '바르고는': 790, '달음으로': 791, '칡덩굴': 792, '데로': 793, '내려가': 794, '이빨로': 795, '끊어': 796, '올라온다': 797, '“저기': 798, '”누렁': 799, '송아지였다': 800, '코뚜레도': 801, '꿰지': 802, '바투': 803, '쥐고': 804, '긁어': 805, '주는': 806, '훌쩍': 807, '올라탔다': 808, '껑충거리며': 809, '돌아간다': 810, '스웨터가': 811, '남색': 812, '스커트가': 813, '꽃과': 814, '함께': 815, '범벅이': 816, '된다': 817, '모두가': 818, '하나의': 819, '내리지': 820, '않으리라': 821, '자랑스러웠다': 822, '이것만은': 823, '흉내': 824, '내지': 825, '못할': 826, '혼자만이': 827, '일인': 828, '“너희': 829, '예서': 830, '뭣들': 831, '하느냐': 832, '”농부': 833, '農夫': 834, '하나가': 835, '억새풀': 836, '사이로': 837, '뛰어내렸다': 838, '송아지를': 839, '타서': 840, '허리가': 841, '상하면': 842, '어쩌느냐고': 843, '꾸지람을': 844, '들을': 845, '나룻이': 846, '긴': 847, '농부는': 848, '편을': 849, '훑어보고는': 850, '풀어': 851, '내면서': 852, '“어서들': 853, '가거라': 854, '소나기가': 855, '올라': 856, '”참': 857, '먹장구름': 858, '장이': 859, '머리': 860, '위에': 861, '사면이': 862, '소란스러워진': 863, '바람이': 864, '우수수': 865, '소리를': 866, '내며': 867, '지나간다': 868, '삽시간에': 869, '보랏빛으로': 870, '변했다': 871, '내려오는데': 872, '떡갈나무': 873, '잎에서': 874, '빗방울': 875, '듣는': 876, '빗방울이었다': 877, '선뜻선뜻했다': 878, '그러자': 879, '대번에': 880, '눈앞을': 881, '가로막는': 882, '빗줄기': 883, '비안개': 884, '속에': 885, '원두막이': 886, '수밖에': 887, '원두막은': 888, '기둥이': 889, '기울고': 890, '지붕도': 891, '갈래갈래': 892, '찢어져': 893, '그런대로': 894, '새는': 895, '곳을': 896, '가려': 897, '들어서게': 898, '입술이': 899, '파아랗게': 900, '질렸다': 901, '떨었다': 902, '무명': 903, '겹저고리를': 904, '싸': 905, '쳐다보았을': 906, '대로': 907, '잠자코': 908, '속에서': 909, '가지가': 910, '꺾이고': 911, '일그러진': 912, '발밑에': 913, '버린다': 914, '들어선': 915, '곳도': 916, '새기': 917, '거기서': 918, '밖을': 919, '내다보던': 920, '생각했는지': 921, '수수밭': 922, '쪽으로': 923, '보더니': 924, '옆의': 925, '날라다': 926, '덧세운다': 927, '본다': 928, '이쪽을': 929, '손짓을': 930, '속은': 931, '비는': 932, '새었다': 933, '어둡고': 934, '좁은': 935, '앞에': 936, '나앉은': 937, '맞아야만': 938, '그런': 939, '어깨에서': 940, '김이': 941, '올랐다': 942, '속삭이듯이': 943, '이리': 944, '괜찮다고': 945, '뒷걸음질을': 946, '쳤다': 947, '바람에': 948, '꽃묶음이': 949, '망그러졌다': 950, '상관없다고': 951, '생각했다': 952, '코에': 953, '끼얹혀졌다': 954, '돌리지': 955, '도리어': 956, '기운으로': 957, '해서': 958, '떨리던': 959, '몸이': 960, '적이': 961, '누그러지는': 962, '느낌이었다': 963, '소란하던': 964, '수숫잎': 965, '뚝': 966, '그쳤다': 967, '밖이': 968, '멀개졌다': 969, '멀지': 970, '않은': 971, '앞쪽에': 972, '햇빛이': 973, '눈부시게': 974, '내리붓고': 975, '도랑': 976, '곳까지': 977, '보니': 978, '엄청나게': 979, '불어': 980, '빛마저': 981, '제법': 982, '붉은': 983, '흙탕물이었다': 984, '건널': 985, '수가': 986, '돌려': 987, '댔다': 988, '순순히': 989, '업히었다': 990, '잠방이까지': 991, '‘어머나’소리를': 992, '지르며': 993, '목을': 994, '끌어안았다': 995, '다다르기': 996, '그랬는가': 997, '싶게': 998, '구름': 999, '점': 1000, '개어': 1001, '뒤로': 1002, '모습은': 1003, '매일같이': 1004, '달려와': 1005, '봐도': 1006, '쉬는': 1007, '시간에': 1008, '운동장을': 1009, '살피기도': 1010, '남': 1011, '5학년': 1012, '여자': 1013, '반을': 1014, '엿보기도': 1015, '그날도': 1016, '조약돌만': 1017, '그랬더니': 1018, '아닌가': 1019, '가슴부터': 1020, '두근거렸다': 1021, '“그동안': 1022, '앓았다': 1023, '”어쩐지': 1024, '해쓱해져': 1025, '“그날': 1026, '소나기': 1027, '맞은': 1028, '탓': 1029, '아냐': 1030, '끄덕이었다': 1031, '“인제': 1032, '났냐': 1033, '”“아직도……': 1034, '누워': 1035, '있어야지': 1036, '”“하도': 1037, '갑갑해서': 1038, '……참': 1039, '재밌었어……': 1040, '어디서': 1041, '들었는지': 1042, '잘': 1043, '지지': 1044, '앞자락을': 1045, '내려다본다': 1046, '거기에': 1047, '검붉은': 1048, '진흙물': 1049, '“그래': 1050, '물': 1051, '같니': 1052, '앞자락만': 1053, '바라보고': 1054, '“내': 1055, '생각해': 1056, '냈다': 1057, '도랑을': 1058, '건너면서': 1059, '업힌': 1060, '일이': 1061, '그때': 1062, '네': 1063, '옮은': 1064, '물이다': 1065, '달아오름을': 1066, '소녀는“저': 1067, '아침에': 1068, '집에서': 1069, '대추를': 1070, '땄다': 1071, '낼': 1072, '지내려고……': 1073, '”대추': 1074, '줌을': 1075, '내준다': 1076, '주춤한다': 1077, '“맛봐라': 1078, '증조': 1079, '曾祖': 1080, '할아버지가': 1081, '심었다는데': 1082, '달다': 1083, '오그려': 1084, '내밀며': 1085, '알도': 1086, '굵다': 1087, '”“그리고': 1088, '이번에': 1089, '지내고': 1090, '집을': 1091, '내주게': 1092, '이사해': 1093, '오기': 1094, '이야기를': 1095, '들어서': 1096, '손자': 1097, '孫子': 1098, '서울서': 1099, '사업에': 1100, '실패해': 1101, '고향에': 1102, '돌아오지': 1103, '않을': 1104, '없게': 1105, '되었다는': 1106, '알고': 1107, '그것이': 1108, '고향': 1109, '넘기게': 1110, '된': 1111, '모양이었다': 1112, '“왜': 1113, '그런지': 1114, '싫어졌다': 1115, '어른들이': 1116, '일이니': 1117, '어쩔': 1118, '없지만……': 1119, '”전에': 1120, '까만': 1121, '쓸쓸한': 1122, '빛이': 1123, '떠돌았다': 1124, '소녀와': 1125, '헤어져': 1126, '혼잣속으로': 1127, '이사를': 1128, '되뇌어': 1129, '무어': 1130, '안타까울': 1131, '서러울': 1132, '그렇건만': 1133, '씹고': 1134, '대추알의': 1135, '단맛을': 1136, '모르고': 1137, '밭으로': 1138, '낯에': 1139, '나무로': 1140, '가지를': 1141, '내리쳤다': 1142, '송이': 1143, '떨어지는': 1144, '별나게': 1145, '크게': 1146, '들렸다': 1147, '가슴이': 1148, '선뜩했다': 1149, '순간': 1150, '호두야': 1151, '모를': 1152, '힘에': 1153, '이끌려': 1154, '마구': 1155, '내리치는': 1156, '열': 1157, '이틀': 1158, '달이': 1159, '지우는': 1160, '그늘만': 1161, '디뎠다': 1162, '그늘의': 1163, '고마움을': 1164, '처음': 1165, '불룩한': 1166, '주머니를': 1167, '어루만졌다': 1168, '맨손으로': 1169, '깠다가는': 1170, '옴이': 1171, '오르기': 1172, '쉽다는': 1173, '말': 1174, '아무렇지도': 1175, '근동에서': 1176, '제일': 1177, '호두를': 1178, '어서': 1179, '맛': 1180, '보여야': 1181, '생각만이': 1182, '앞섰다': 1183, '그러다': 1184, '아차': 1185, '들었다': 1186, '소녀더러': 1187, '병이': 1188, '낫거들랑': 1189, '가기': 1190, '나와': 1191, '달라는': 1192, '둔': 1193, '이튿날': 1194, '돌아오니': 1195, '나들이옷으로': 1196, '갈아입고': 1197, '닭': 1198, '마리를': 1199, '물었다': 1200, '말에도': 1201, '대꾸도': 1202, '닭의': 1203, '무게를': 1204, '겨냥해': 1205, '보면서': 1206, '“이만하면': 1207, '”어머니가': 1208, '망태기를': 1209, '내주며': 1210, '“벌써': 1211, '‘걀걀’하고': 1212, '자리를': 1213, '보던데요': 1214, '크진': 1215, '않아도': 1216, '살은': 1217, '쪘을': 1218, '거여요': 1219, '어머니한테': 1220, '물어보았다': 1221, '“저': 1222, '댁에': 1223, '가신다': 1224, '제사상에라도': 1225, '놓으시라고……': 1226, '놈으로': 1227, '가져가지': 1228, '얼룩': 1229, '수탉으로……': 1230, '”이': 1231, '말에': 1232, '허허': 1233, '웃고': 1234, '인마': 1235, '그래도': 1236, '실속이': 1237, '공연히': 1238, '열적어': 1239, '책': 1240, '보를': 1241, '집어던지고는': 1242, '외양간으로': 1243, '쇠잔': 1244, '철썩': 1245, '갈겼다': 1246, '쇠파리라도': 1247, '개울물은': 1248, '날로': 1249, '여물어': 1250, '아래쪽으로': 1251, '갈밭머리에서': 1252, '바라보는': 1253, '마을은': 1254, '쪽빛': 1255, '하늘': 1256, '한결': 1257, '가까워': 1258, '양평읍으로': 1259, '거기': 1260, '가서는': 1261, '조그마한': 1262, '가겟방을': 1263, '비게': 1264, '되리라는': 1265, '알을': 1266, '손으로는': 1267, '휘어': 1268, '꺾고': 1269, '자리에': 1270, '누워서도': 1271, '생각뿐이었다': 1272, '이사하는': 1273, '보나': 1274, '어쩌나': 1275, '가면': 1276, '보게': 1277, '어떨까': 1278, '까무룩': 1279, '잠이': 1280, '들었는가': 1281, '하는데': 1282, '“허': 1283, '세상일도……': 1284, '”마을': 1285, '갔던': 1286, '돌아왔는지': 1287, '“윤': 1288, '댁도': 1289, '아니야': 1290, '많던': 1291, '전답을': 1292, '팔아': 1293, '버리고': 1294, '대대로': 1295, '살아오던': 1296, '넘기더니': 1297, '악상까지': 1298, '당하는': 1299, '보면……': 1300, '”남폿불': 1301, '바느질감을': 1302, '어머니가': 1303, '“증손': 1304, '曾孫': 1305, '이라곤': 1306, '하나뿐이었지요': 1307, '”“그렇지': 1308, '사내': 1309, '둘': 1310, '어려서': 1311, '잃어버리고……': 1312, '”“어쩌면': 1313, '그렇게': 1314, '자식복이': 1315, '없을까': 1316, '”“글쎄': 1317, '말이지': 1318, '앤': 1319, '여러': 1320, '앓는': 1321, '약도': 1322, '변변히': 1323, '못써': 1324, '봤다더군': 1325, '같아서': 1326, '초시네도': 1327, '대가': 1328, '끊긴': 1329, '셈이지': 1330, '……그런데': 1331, '것이': 1332, '여간': 1333, '잔망스럽지가': 1334, '글쎄': 1335, '죽기': 1336, '했다지': 1337, '죽거든': 1338, '입던': 1339, '옷을': 1340, '꼭': 1341, '입혀서': 1342, '묻어': 1343, '달라고……': 1344, '”': 1345}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "for line in text.split('\\n'): # 줄바꿈 문자를 기준으로 문장 토큰화\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpvva4_w1_hX",
        "outputId": "c0fcbc92-0dfe-40df-fea3-6a2723feb5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습에 사용할 샘플의 개수: 1702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in sequences) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
        "print(max_len)\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yho-uIM42Dds",
        "outputId": "201bcbe4-cec0-467a-ba25-722abdd46722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "owIYZj-e2KBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LSTM"
      ],
      "metadata": {
        "id": "I2v5u4EU2Fu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10\n",
        "hidden_units = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C7fnhnC2Oho",
        "outputId": "1db263fc-240c-418e-b103-4505e137e168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "54/54 [==============================] - 3s 14ms/step - loss: 7.2075 - accuracy: 0.0082\n",
            "Epoch 2/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 7.1867 - accuracy: 0.0118\n",
            "Epoch 3/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 7.1315 - accuracy: 0.0141\n",
            "Epoch 4/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.9741 - accuracy: 0.0141\n",
            "Epoch 5/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.9268 - accuracy: 0.0141\n",
            "Epoch 6/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.9089 - accuracy: 0.0141\n",
            "Epoch 7/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.8879 - accuracy: 0.0141\n",
            "Epoch 8/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.8567 - accuracy: 0.0141\n",
            "Epoch 9/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.8164 - accuracy: 0.0141\n",
            "Epoch 10/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.7622 - accuracy: 0.0141\n",
            "Epoch 11/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.6975 - accuracy: 0.0141\n",
            "Epoch 12/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.6178 - accuracy: 0.0153\n",
            "Epoch 13/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.5333 - accuracy: 0.0170\n",
            "Epoch 14/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 6.4471 - accuracy: 0.0182\n",
            "Epoch 15/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 6.3654 - accuracy: 0.0200\n",
            "Epoch 16/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 6.2846 - accuracy: 0.0194\n",
            "Epoch 17/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 6.2068 - accuracy: 0.0200\n",
            "Epoch 18/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.1338 - accuracy: 0.0194\n",
            "Epoch 19/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 6.0629 - accuracy: 0.0206\n",
            "Epoch 20/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 5.9949 - accuracy: 0.0212\n",
            "Epoch 21/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 5.9274 - accuracy: 0.0200\n",
            "Epoch 22/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 5.8634 - accuracy: 0.0264\n",
            "Epoch 23/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.7993 - accuracy: 0.0253\n",
            "Epoch 24/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.7384 - accuracy: 0.0300\n",
            "Epoch 25/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.6781 - accuracy: 0.0300\n",
            "Epoch 26/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.6197 - accuracy: 0.0317\n",
            "Epoch 27/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.5615 - accuracy: 0.0282\n",
            "Epoch 28/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.5061 - accuracy: 0.0358\n",
            "Epoch 29/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.4519 - accuracy: 0.0358\n",
            "Epoch 30/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 5.4009 - accuracy: 0.0429\n",
            "Epoch 31/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.3500 - accuracy: 0.0470\n",
            "Epoch 32/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.2998 - accuracy: 0.0494\n",
            "Epoch 33/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.2477 - accuracy: 0.0511\n",
            "Epoch 34/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.2035 - accuracy: 0.0629\n",
            "Epoch 35/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.1532 - accuracy: 0.0611\n",
            "Epoch 36/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 5.1038 - accuracy: 0.0723\n",
            "Epoch 37/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 5.0573 - accuracy: 0.0758\n",
            "Epoch 38/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 5.0108 - accuracy: 0.0758\n",
            "Epoch 39/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.9670 - accuracy: 0.0846\n",
            "Epoch 40/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.9234 - accuracy: 0.0917\n",
            "Epoch 41/200\n",
            "54/54 [==============================] - 1s 13ms/step - loss: 4.8802 - accuracy: 0.0993\n",
            "Epoch 42/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.8343 - accuracy: 0.1005\n",
            "Epoch 43/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.7921 - accuracy: 0.1110\n",
            "Epoch 44/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.7494 - accuracy: 0.1116\n",
            "Epoch 45/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 4.7091 - accuracy: 0.1152\n",
            "Epoch 46/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.6683 - accuracy: 0.1240\n",
            "Epoch 47/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.6253 - accuracy: 0.1345\n",
            "Epoch 48/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.5835 - accuracy: 0.1439\n",
            "Epoch 49/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 4.5433 - accuracy: 0.1451\n",
            "Epoch 50/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.5052 - accuracy: 0.1539\n",
            "Epoch 51/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.4642 - accuracy: 0.1639\n",
            "Epoch 52/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 4.4244 - accuracy: 0.1686\n",
            "Epoch 53/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.3879 - accuracy: 0.1698\n",
            "Epoch 54/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.3475 - accuracy: 0.1816\n",
            "Epoch 55/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.3103 - accuracy: 0.1962\n",
            "Epoch 56/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.2688 - accuracy: 0.2062\n",
            "Epoch 57/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.2323 - accuracy: 0.2109\n",
            "Epoch 58/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 4.1944 - accuracy: 0.2286\n",
            "Epoch 59/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 4.1553 - accuracy: 0.2333\n",
            "Epoch 60/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 4.1176 - accuracy: 0.2397\n",
            "Epoch 61/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.0807 - accuracy: 0.2526\n",
            "Epoch 62/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 4.0449 - accuracy: 0.2662\n",
            "Epoch 63/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 4.0071 - accuracy: 0.2744\n",
            "Epoch 64/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 3.9717 - accuracy: 0.2826\n",
            "Epoch 65/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 3.9352 - accuracy: 0.2902\n",
            "Epoch 66/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 3.8989 - accuracy: 0.2973\n",
            "Epoch 67/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.8615 - accuracy: 0.3102\n",
            "Epoch 68/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.8255 - accuracy: 0.3173\n",
            "Epoch 69/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 3.7898 - accuracy: 0.3320\n",
            "Epoch 70/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 3.7529 - accuracy: 0.3390\n",
            "Epoch 71/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.7179 - accuracy: 0.3555\n",
            "Epoch 72/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 3.6865 - accuracy: 0.3584\n",
            "Epoch 73/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 3.6476 - accuracy: 0.3737\n",
            "Epoch 74/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 3.6136 - accuracy: 0.3843\n",
            "Epoch 75/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 3.5761 - accuracy: 0.3860\n",
            "Epoch 76/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.5414 - accuracy: 0.3972\n",
            "Epoch 77/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.5081 - accuracy: 0.4013\n",
            "Epoch 78/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.4738 - accuracy: 0.4089\n",
            "Epoch 79/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 3.4384 - accuracy: 0.4154\n",
            "Epoch 80/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 3.4056 - accuracy: 0.4236\n",
            "Epoch 81/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.3735 - accuracy: 0.4407\n",
            "Epoch 82/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.3399 - accuracy: 0.4436\n",
            "Epoch 83/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.3034 - accuracy: 0.4600\n",
            "Epoch 84/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 3.2742 - accuracy: 0.4559\n",
            "Epoch 85/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 3.2370 - accuracy: 0.4788\n",
            "Epoch 86/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 3.2044 - accuracy: 0.4906\n",
            "Epoch 87/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.1721 - accuracy: 0.4894\n",
            "Epoch 88/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.1397 - accuracy: 0.5024\n",
            "Epoch 89/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.1075 - accuracy: 0.5024\n",
            "Epoch 90/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.0717 - accuracy: 0.5176\n",
            "Epoch 91/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.0401 - accuracy: 0.5264\n",
            "Epoch 92/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 3.0070 - accuracy: 0.5282\n",
            "Epoch 93/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.9746 - accuracy: 0.5429\n",
            "Epoch 94/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.9442 - accuracy: 0.5482\n",
            "Epoch 95/200\n",
            "54/54 [==============================] - 1s 13ms/step - loss: 2.9144 - accuracy: 0.5582\n",
            "Epoch 96/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.8838 - accuracy: 0.5629\n",
            "Epoch 97/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.8484 - accuracy: 0.5752\n",
            "Epoch 98/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.8168 - accuracy: 0.5834\n",
            "Epoch 99/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.7853 - accuracy: 0.5922\n",
            "Epoch 100/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.7560 - accuracy: 0.5922\n",
            "Epoch 101/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 2.7262 - accuracy: 0.5969\n",
            "Epoch 102/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.6962 - accuracy: 0.6046\n",
            "Epoch 103/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.6657 - accuracy: 0.6110\n",
            "Epoch 104/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.6347 - accuracy: 0.6157\n",
            "Epoch 105/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.6073 - accuracy: 0.6193\n",
            "Epoch 106/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 2.5783 - accuracy: 0.6281\n",
            "Epoch 107/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.5504 - accuracy: 0.6363\n",
            "Epoch 108/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.5213 - accuracy: 0.6287\n",
            "Epoch 109/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 2.4937 - accuracy: 0.6422\n",
            "Epoch 110/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.4603 - accuracy: 0.6498\n",
            "Epoch 111/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 2.4298 - accuracy: 0.6622\n",
            "Epoch 112/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.4181 - accuracy: 0.6569\n",
            "Epoch 113/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.3810 - accuracy: 0.6733\n",
            "Epoch 114/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.3483 - accuracy: 0.6733\n",
            "Epoch 115/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.3209 - accuracy: 0.6821\n",
            "Epoch 116/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.2971 - accuracy: 0.6863\n",
            "Epoch 117/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.2689 - accuracy: 0.6910\n",
            "Epoch 118/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.2408 - accuracy: 0.6998\n",
            "Epoch 119/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.2132 - accuracy: 0.7051\n",
            "Epoch 120/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.1877 - accuracy: 0.7074\n",
            "Epoch 121/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.1638 - accuracy: 0.7127\n",
            "Epoch 122/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 2.1375 - accuracy: 0.7139\n",
            "Epoch 123/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.1109 - accuracy: 0.7244\n",
            "Epoch 124/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.0865 - accuracy: 0.7221\n",
            "Epoch 125/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 2.0628 - accuracy: 0.7268\n",
            "Epoch 126/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 2.0365 - accuracy: 0.7333\n",
            "Epoch 127/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.0150 - accuracy: 0.7338\n",
            "Epoch 128/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.9948 - accuracy: 0.7403\n",
            "Epoch 129/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.9689 - accuracy: 0.7421\n",
            "Epoch 130/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.9413 - accuracy: 0.7491\n",
            "Epoch 131/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.9172 - accuracy: 0.7509\n",
            "Epoch 132/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.8960 - accuracy: 0.7550\n",
            "Epoch 133/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.8709 - accuracy: 0.7603\n",
            "Epoch 134/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.8511 - accuracy: 0.7597\n",
            "Epoch 135/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.8289 - accuracy: 0.7638\n",
            "Epoch 136/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.8099 - accuracy: 0.7691\n",
            "Epoch 137/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.7879 - accuracy: 0.7714\n",
            "Epoch 138/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.7663 - accuracy: 0.7714\n",
            "Epoch 139/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.7444 - accuracy: 0.7791\n",
            "Epoch 140/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.7204 - accuracy: 0.7773\n",
            "Epoch 141/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.6977 - accuracy: 0.7873\n",
            "Epoch 142/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.6811 - accuracy: 0.7803\n",
            "Epoch 143/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.6615 - accuracy: 0.7861\n",
            "Epoch 144/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.6422 - accuracy: 0.7914\n",
            "Epoch 145/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.6224 - accuracy: 0.7920\n",
            "Epoch 146/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.5980 - accuracy: 0.7914\n",
            "Epoch 147/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.5788 - accuracy: 0.7961\n",
            "Epoch 148/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.5609 - accuracy: 0.7996\n",
            "Epoch 149/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.5416 - accuracy: 0.8020\n",
            "Epoch 150/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.5276 - accuracy: 0.8055\n",
            "Epoch 151/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.5057 - accuracy: 0.8114\n",
            "Epoch 152/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.4859 - accuracy: 0.8114\n",
            "Epoch 153/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.4702 - accuracy: 0.8102\n",
            "Epoch 154/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.4503 - accuracy: 0.8137\n",
            "Epoch 155/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.4323 - accuracy: 0.8149\n",
            "Epoch 156/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.4164 - accuracy: 0.8173\n",
            "Epoch 157/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3977 - accuracy: 0.8226\n",
            "Epoch 158/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.3808 - accuracy: 0.8255\n",
            "Epoch 159/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3719 - accuracy: 0.8267\n",
            "Epoch 160/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.3522 - accuracy: 0.8273\n",
            "Epoch 161/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.3345 - accuracy: 0.8231\n",
            "Epoch 162/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.3181 - accuracy: 0.8308\n",
            "Epoch 163/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.2996 - accuracy: 0.8331\n",
            "Epoch 164/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.2838 - accuracy: 0.8384\n",
            "Epoch 165/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.2700 - accuracy: 0.8414\n",
            "Epoch 166/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.2550 - accuracy: 0.8402\n",
            "Epoch 167/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.2392 - accuracy: 0.8402\n",
            "Epoch 168/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.2251 - accuracy: 0.8455\n",
            "Epoch 169/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.2097 - accuracy: 0.8443\n",
            "Epoch 170/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1934 - accuracy: 0.8472\n",
            "Epoch 171/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.1803 - accuracy: 0.8531\n",
            "Epoch 172/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.1660 - accuracy: 0.8490\n",
            "Epoch 173/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.1541 - accuracy: 0.8472\n",
            "Epoch 174/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.1395 - accuracy: 0.8496\n",
            "Epoch 175/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1273 - accuracy: 0.8537\n",
            "Epoch 176/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.1182 - accuracy: 0.8496\n",
            "Epoch 177/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.1075 - accuracy: 0.8549\n",
            "Epoch 178/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.0891 - accuracy: 0.8602\n",
            "Epoch 179/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.0738 - accuracy: 0.8660\n",
            "Epoch 180/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 1.0613 - accuracy: 0.8613\n",
            "Epoch 181/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0479 - accuracy: 0.8631\n",
            "Epoch 182/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.0394 - accuracy: 0.8678\n",
            "Epoch 183/200\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0248 - accuracy: 0.8684\n",
            "Epoch 184/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 1.0104 - accuracy: 0.8696\n",
            "Epoch 185/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.9991 - accuracy: 0.8707\n",
            "Epoch 186/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.9860 - accuracy: 0.8719\n",
            "Epoch 187/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.9755 - accuracy: 0.8725\n",
            "Epoch 188/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.9657 - accuracy: 0.8713\n",
            "Epoch 189/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.9548 - accuracy: 0.8760\n",
            "Epoch 190/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.9416 - accuracy: 0.8790\n",
            "Epoch 191/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.9324 - accuracy: 0.8743\n",
            "Epoch 192/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.9207 - accuracy: 0.8790\n",
            "Epoch 193/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.9094 - accuracy: 0.8760\n",
            "Epoch 194/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8999 - accuracy: 0.8837\n",
            "Epoch 195/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.8920 - accuracy: 0.8778\n",
            "Epoch 196/200\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.8802 - accuracy: 0.8825\n",
            "Epoch 197/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8749 - accuracy: 0.8819\n",
            "Epoch 198/200\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.8604 - accuracy: 0.8848\n",
            "Epoch 199/200\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.8502 - accuracy: 0.8895\n",
            "Epoch 200/200\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8401 - accuracy: 0.8890\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a58623990>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "_u0-6tdt2Wfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '경마장에', 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGK9Icj82bZJ",
        "outputId": "a58c6643-3562-4321-9acd-37bd5f98e2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소년은 저도 모르게 주머니 속 호두 알을 만지작거리며 한 손으로는 수없이 갈꽃을 휘어 꺾고 있었다 대로 잠자코 있었다 대로 잠자코 있었다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '그의', 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPrUpwwW2dsg",
        "outputId": "6ad28a39-ba7e-4927-e97a-608190f22ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그의 말이 법이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '가는', 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVYDzjEU2fKS",
        "outputId": "2a1187bd-f4c5-46fb-cc3e-06d509d854a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가는 소녀는 학교에서 잠그고 물장난을 하던\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '소년은', 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAalsyrDAgdZ",
        "outputId": "d3fcea82-f7da-4b40-d383-f95ec9aeea9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소년은 저도 모르게 주머니 속 호두 알을 만지작거리며 한 손으로는 수없이 갈꽃을 휘어 꺾고 있었다 대로 잠자코 있었다 대로 잠자코 있었다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '소년은 공연히', 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoC2upmSAnmu",
        "outputId": "2b8f1494-c194-4685-8857-7c11e0fc9d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소년은 공연히 열적어 책 보를 집어던지고는 외양간으로 가 쇠잔 시작했다 있다 가에 앉아 있는 것이다 들어서 것이다 들어서 것이다 들어서 가 서울서\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '그 날 밤', 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvCHIdoaA7f3",
        "outputId": "57a9b74a-a3ac-45b7-d77c-8ffe86ec149a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그 날 밤 가을 하늘이 언제 그랬는가 싶게 구름 한 점 움켜 낸다 개어 있었다 쪽빛으로 수없이 앉아 있었다 대로 잠자코 있었다 수없이\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "YF9b5mt88dK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QlDaY7Q8lrk",
        "outputId": "634806ff-7736-4a76-d639-2e71b7384757"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('drive/MyDrive/colab_test/소나기.txt', 'r', encoding='UTF-8')\n",
        "lines = text.readlines()"
      ],
      "metadata": {
        "id": "wyXfEotA50sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9E2B61j9MYd",
        "outputId": "16264bac-f0f6-4eb8-efa1-0b20c3185462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 날은 좀 늦게 개울가로 나왔다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git\n",
        "from hanspell import spell_checker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ7iSB6I6ys3",
        "outputId": "7a7b7337-ee50-4d1f-c0e3-d8a2ffb2cc15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-5onqikiy\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-5onqikiy\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4868 sha256=6c8d85687510872de4ebb5e21395fae4648cd45aff19cfa181d6dbf789a75b58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-llqm4ul0/wheels/ab/f5/7b/d4124bb329c905301baed80e2ae45aa14e824f62ebc3ec2cc4\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(lines)):\n",
        "  text_spell = spell_checker.check(lines[i])\n",
        "  lines[i] = text_spell.checked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "jXVg_ZbP7Bch",
        "outputId": "954326cb-0f56-4699-88a8-fb9eb45dada8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-f9a5f8e5ff65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtext_spell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspell_checker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_spell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hanspell/spell_checker.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mpassed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHeO1brE-_kn",
        "outputId": "a44e5faf-61b3-4bac-e08d-f3af3744d664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女) 딸이라는 걸 알 수 있었다. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''.join(lines)"
      ],
      "metadata": {
        "id": "ofbtbq-x7Lvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace('”', '')\n",
        "text = text.replace('‘','')\n",
        "text = text.replace('“','')"
      ],
      "metadata": {
        "id": "m1fj7W4kBTUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = text.split('.')\n",
        "print(text_list[0])\n",
        "text = '\\n'.join(text_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpUyt78G-Gdq",
        "outputId": "b42b54a3-dd8d-4bd1-fdd2-2345d7cfe4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女) 딸이라는 걸 알 수 있었다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gckt_uNd-VcO",
        "outputId": "27a23571-3395-445d-87bc-6314bce7a199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女) 딸이라는 걸 알 수 있었다\n",
            " 소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다\n",
            " 서울 서는 이런 개울물을 보지 못하기나 한 듯이\n",
            " 벌써 며칠째 소녀는, 학교에서 돌아오는 길에 물장난이었다\n",
            " 그런데, 어제까지 개울 기슭에서 하더니, 오늘은 징검다리 한가운데 앉아서 하고 있다\n",
            " 소년은 개울 뚝에 앉아 버렸다\n",
            " 소녀가 비키기를 기다리자는 것이다\n",
            " 요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다\n",
            "다음 날은 좀 늦게 개울가로 나왔다\n",
            "이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다\n",
            " 분홍 스웨터 소매를 걷어올린 목덜미가 마냥 희었다\n",
            "한참 세수를 하고 나더니, 이번에는 물속을 빤히 들여다본다\n",
            " 얼굴이라도 비추어 보는 것이리라\n",
            " 갑자기 물을 움켜 낸다\n",
            " 고기 새끼라도 지나가는 듯\n",
            "소녀는 소년이 개울 뚝에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다\n",
            " 그러나, 번번이 허탕이다\n",
            " 그대로 재미있는 양, 자꾸 물만 움킨다\n",
            " 어제처럼 개울을 건너는 사람이 있어야 길을 비킬 모양이다\n",
            "그러다가 소녀가 물속에서 무엇을 하나 집어 낸다\n",
            " 하얀 조약돌이었다\n",
            " 그리고는 벌떡 일어나 팔짝팔짝 징검다리를 뛰어 건너간다\n",
            "다 건너가더니만 홱 이리로 돌아서며,이 바보\n",
            "조약돌이 날아왔다\n",
            "소년은 저도 모르게 벌떡 일어섰다\n",
            "단발머리를 나풀거리며 소녀가 막 달린다\n",
            " 갈밭 사잇길로 들어섰다\n",
            " 뒤에는 청량한 가을 햇살 아래 빛나는 갈꽃뿐\n",
            "이제 저쯤 갈밭머리로 소녀가 나타나리라\n",
            " 꽤 오랜 시간이 지났다고 생각됐다\n",
            " 그런데도 소녀는 나타나지 않는다\n",
            " 발돋움을 했다\n",
            " 그러고도 상당한 시간이 지났다고 생각됐다\n",
            "저쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다\n",
            " 소녀가 갈꽃을 안고 있었다\n",
            " 그리고, 이제는 천천한 걸음이었다\n",
            " 유난히 맑은 가을 햇살이 소녀의 갈꽃 머리에서 반짝거렸다\n",
            " 소녀 아닌 갈꽃이 들길을 걸어가는 것만 같았다\n",
            "소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다\n",
            " 문득, 소녀 가던지 조약돌을 내려다보았다\n",
            " 물기가 걷혀 있었다\n",
            " 소년은 조약돌을 집어 주머니에 넣었다\n",
            "다음 날부터 좀 더 늦게 개울가로 나왔다\n",
            " 소녀의 그림자가 뵈지 않았다\n",
            " 다행이었다\n",
            "그러나, 이상한 일이었다\n",
            " 소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한구석에는 어딘가 허전함이 자리 잡는 것이었다\n",
            " 주머니 속 조약돌을 주무르는 버릇이 생겼다\n",
            "그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았다\n",
            " 물속에 손을 잠갔다\n",
            " 세수를 하였다\n",
            " 물속을 들여다보았다\n",
            " 검게 탄 얼굴이 그대로 비치었다\n",
            " 싫었다\n",
            "소년은 두 손으로 물속의 얼굴을 움키었다\n",
            " 몇 번이고 움키었다\n",
            " 그러다가 깜짝 놀라 일어나고 말았다\n",
            " 소녀가 이리로 건너오고 있지 않느냐\n",
            "숨어서 내가 하는 일을 엿보고 있었구나\n",
            "’ 소년은 달리기를 시작했다\n",
            " 디딤돌을 헛디뎠다\n",
            " 한 발이 물속에 빠졌다\n",
            " 더 달렸다\n",
            "몸을 가릴 데가 있어 줬으면 좋겠다\n",
            " 이쪽 길에는 갈밭도 없다\n",
            " 메밀 밭이다\n",
            " 전에 없이 메밀꽃 냄새가 짜릿하게 코를 찌른다고 생각됐다\n",
            " 미간이 아찔했다\n",
            " 찝찔한 액체가 입술에 흘러들었다\n",
            " 코피였다\n",
            "소년은 한 손으로 코피를 훔쳐내면서 그냥 달렸다\n",
            " 어디선가 바보, 바보’ 하는 소리가 자꾸만 뒤따라오는 것 같았다\n",
            "토요일이었다\n",
            "개울가에 이르니, 며칠째 보이지 않던 소녀가 건너편 가에 앉아 물장난을 하고 있었다\n",
            " 모르는 체 징검다리를 건너기 시작했다\n",
            " 얼마 전에 소녀 앞에서 한 번 실수를 했을 뿐, 여태 큰길 가듯이 건너던 징검다리를 오늘은 조심스럽게 건넌다\n",
            "얘\n",
            "못 들은 체했다\n",
            " 둑 위로 올라섰다\n",
            "얘, 이게 무슨 조 개지?자기도 모르게 돌아섰다\n",
            " 소녀의 맑고 검은 눈과 마주쳤다\n",
            " 얼른 소녀의 손바닥으로 눈을 떨구었다\n",
            "비단 조개\n",
            "이름도 참 곱다\n",
            "갈림길에 왔다\n",
            " 여기서 소녀는 아래편으로 한 삼 마장쯤, 소년은 우대로 한 십 리 가까운 길을 가야 한다\n",
            "소녀가 걸음을 멈추며,너, 저 산 너머에 가 본 일 있니?벌 끝을 가리켰다\n",
            "없다\n",
            "우리, 가 보지 않으련? 시골 오니까 혼자서 심심해 못 견디겠다\n",
            "저래 봬도 멀다\n",
            "멀면 얼마나 멀기에? 서울 있을 땐 사뭇 먼 데까지 소풍 갔었다\n",
            "소녀의 눈이 금세 바보, 바보,’할 것만 같았다\n",
            "논 사잇길로 들어섰다\n",
            " 벼 가을걷이는 곁을 지났다\n",
            "허수아비가 서 있었다\n",
            " 소년이 새끼줄을 흔들었다\n",
            " 참새가 몇 마리 날아간다\n",
            " 참, 오늘은 일찍 집으로 돌아가 텃논의 참새를 봐야 할걸\n",
            "’ 하는 생각이 든다\n",
            "야, 재밌다!소녀가 허수아비 줄을 잡더니 흔들어 댄다\n",
            " 허수아비가 자꾸 우쭐거리며 춤을 춘다\n",
            " 소녀의 왼쪽 볼에 살포시 보조개가 패었다\n",
            "저만큼 허수아비가 또 서 있다\n",
            " 소녀가 그리로 달려간다\n",
            " 그 뒤를 소년도 달렸다\n",
            " 오늘 같은 날은 일찍 집으로 돌아가 집안일을 도와야 한다는 생각을 잊어버리기라도 하려는 듯이\n",
            "소녀의 곁을 스쳐 그냥 달린다\n",
            " 메뚜기가 따끔따끔 얼굴에 와 부딪친다\n",
            " 쪽빛으로 한껏 갠 가을 하늘이 소년의 눈앞에서 맴을 돈다\n",
            " 어지럽다\n",
            " 저놈의 독수리, 저놈의 독수리, 저놈의 독수리가 맴을 돌고 있기 때문이다\n",
            "돌아다보니, 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다\n",
            " 좀 전 허수아비보다 더 우쭐거린다\n",
            "논이 끝난 곳에 도랑이 하나 있었다\n",
            " 소녀가 먼저 뛰어 건넜다\n",
            "거기서부터 산 밑까지는 밭이었다\n",
            "수숫단을 세워 놓은 밭머리를 지났다\n",
            "저게 뭐니?원두막\n",
            "여기 참외, 맛있니?그럼, 참외 맛도 좋지만 수박 맛은 더 좋다\n",
            "하나 먹어 봤으면\n",
            "소년이 참외 그루에 심은 무밭으로 들어가, 무 두 밑을 뽑아 왔다\n",
            " 아직 밑이 덜 들어 있었다\n",
            " 잎을 비틀어 팽개친 후, 소녀에게 한 개 건넨다\n",
            " 그리고는 이렇게 먹어야 한다는 듯이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다\n",
            "소녀도 따라 했다\n",
            " 그러나, 세 입도 못 먹고,아, 맵고 지려\n",
            "하며 집어던지고 만다\n",
            "참, 맛없어 못 먹겠다\n",
            "소년이 더 멀리 팽개쳐 버렸다\n",
            "산이 가까워졌다\n",
            "단풍이 눈에 따가웠다\n",
            "야아!소녀가 산을 향해 달려갔다\n",
            " 이번은 소년이 뒤따라 달리지 않았다\n",
            " 그러고도 곧 소녀보다 더 많은 꽃을 꺾었다\n",
            "이게 들국화, 이게 싸리꽃, 이게 도라지꽃, ……\n",
            "도라지꽃이 이렇게 예쁜 줄은 몰랐네\n",
            " 난 보랏빛이 좋아! …… 그런데, 이 양산같이 생긴 노란 꽃이 뭐지?마타리 꽃\n",
            "소녀는 마타리 꽃을 양산 받듯이 해 보인다\n",
            " 약간 상기된 얼굴에 살포시 보조개를 떠올리며\n",
            "다시 소년은 꽃 한 옴큼을 꺾어 왔다\n",
            " 싱싱한 꽃가지만 골라 소녀에게 건넨다\n",
            "그러나 소녀는하나도 버리지 마라\n",
            "산마루께로 올라갔다\n",
            "맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다\n",
            "누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다\n",
            " 유달리 주위가 조용해진 것 같았다\n",
            " 따가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다\n",
            "저건 또 무슨 꽃이지?적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다\n",
            "꼭 등꽃 같네\n",
            " 서울 우리 학교에 큰 등나무가 있었단다\n",
            " 저 꽃을 보니까 등나무 밑에서 놀던 동무들 생각이 난다\n",
            "소녀가 조용히 일어나 비탈진 곳으로 간다\n",
            " 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한다\n",
            " 좀처럼 끊어지지 않는다\n",
            " 안간힘을 쓰다가 그만 미끄러지고 만다\n",
            " 칡덩굴을 그러쥐었다\n",
            "소년이 놀라 달려갔다\n",
            " 소녀가 손을 내밀었다\n",
            " 손을 잡아 이끌어 올리며, 소년은 제가 꺾어다 줄 것을 잘못했다고 뉘우친다\n",
            " 소녀의 오른쪽 무릎에 핏방울이 내맺혔다\n",
            " 소년은 저도 모르게 생채기에 입술을 가져다 대고 빨기 시작했다\n",
            " 그러다가, 무슨 생각을 했는지 홱 일어나 저쪽으로 달려간다\n",
            "좀 만에 숨이 차 돌아온 소년은이걸 바르면 낫는다\n",
            "송진을 생채기에다 문질러 바르고는 그 달음으로 칡덩굴 있는 데로 내려가, 꽃 많이 달린 몇 줄기를 이빨로 끊어 가지고 올라온다\n",
            " 그리고는,저기 송아지가 있다\n",
            " 그리 가 보자\n",
            "누렁 송아지였다\n",
            " 아직 코뚜레도 꿰지 않았다\n",
            "소년이 고삐를 바투 잡아 쥐고 등을 긁어 주는 체 훌쩍 올라탔다\n",
            " 송아지가 껑충거리며 돌아간다\n",
            "소녀의 흰 얼굴이, 분홍 스웨터가, 남색 스커트가, 안고 있는 꽃과 함께 범벅이 된다\n",
            " 모두가 하나의 큰 꽃묶음 같다\n",
            " 어지럽다\n",
            " 그러나, 내리지 않으리라\n",
            " 자랑스러웠다\n",
            " 이것만은 소녀가 흉내 내지 못할, 자기 혼자만이 할 수 있는 일인 것이다\n",
            "너희, 예서 뭣들 하느냐?농부(農夫) 하나가 억새풀 사이로 올라왔다\n",
            "송아지 등에서 뛰어내렸다\n",
            " 어린 송아지를 타서 허리가 상하면 어쩌느냐고 꾸지람을 들을 것만 같다\n",
            "그런데, 나룻이 긴 농부는 소녀 편을 한 번 훑어보고는 그저 송아지 고삐를 풀어 내면서,어서들 집으로 가거라\n",
            " 소나기가 올라\n",
            "참, 먹장구름 한 장이 머리 위에 와 있다\n",
            " 갑자기 사면이 소란스러워진 것 같다\n",
            " 바람이 우수수 소리를 내며 지나간다\n",
            " 삽시간에 주위가 보랏빛으로 변했다\n",
            "산을 내려오는데, 떡갈나무 잎에서 빗방울 듣는 소리가 난다\n",
            " 굵은 빗방울이었다\n",
            " 목덜미가 선뜻선뜻했다\n",
            " 그러자, 대번에 눈앞을 가로막는 빗줄기\n",
            "비안개 속에 원두막이 보였다\n",
            " 그리로 가 비를 그을 수밖에\n",
            "그러나, 원두막은 기둥이 기울고 지붕도 갈래갈래 찢어져 있었다\n",
            " 그런대로 비가 덜 새는 곳을 가려 소녀를 들어서게 했다\n",
            "소녀의 입술이 파아랗게 질렸다\n",
            " 어깨를 자꾸 떨었다\n",
            "무명 겹저고리를 벗어 소녀의 어깨를 싸 주었다\n",
            " 소녀는 비에 젖은 눈을 들어 한 번 쳐다보았을 뿐, 소년이 하는 대로 잠자코 있었다\n",
            " 그리고는, 안고 온 꽃묶음 속에서 가지가 꺾이고 꽃이 일그러진 송이를 골라 발밑에 버린다\n",
            " 소녀가 들어선 곳도 비가 새기 시작했다\n",
            " 더 거기서 비를 그을 수 없었다\n",
            "밖을 내다보던 소년이 무엇을 생각했는지 수수밭 쪽으로 달려간다\n",
            " 세워 놓은 수숫단 속을 비집어 보더니, 옆의 수숫단을 날라다 덧세운다\n",
            " 다시 속을 비집어 본다\n",
            " 그리고는 이쪽을 향해 손짓을 한다\n",
            "수숫단 속은 비는 안 새었다\n",
            " 그저 어둡고 좁은 게 안 됐다\n",
            " 앞에 나앉은 소년은 그냥 비를 맞아야만 했다\n",
            " 그런 소년의 어깨에서 김이 올랐다\n",
            "소녀가 속삭이듯이, 이리 들어와 앉으라고 했다\n",
            " 괜찮다고 했다\n",
            " 소녀가 다시, 들어와 앉으라고 했다\n",
            " 할 수 없이 뒷걸음질을 쳤다\n",
            " 그 바람에, 소녀가 안고 있는 꽃묶음이 망그러졌다\n",
            " 그러나, 소녀는 상관없다고 생각했다\n",
            " 비에 젖은 소년의 몸 냄새가 확 코에 끼얹혀졌다\n",
            " 그러나, 고개를 돌리지 않았다\n",
            " 도리어 소년의 몸 기운으로 해서 떨리던 몸이 적이 누그러지는 느낌이었다\n",
            "소란하던 수숫잎 소리가 뚝 그쳤다\n",
            " 밖이 멀개졌다\n",
            "수숫단 속을 벗어 나왔다\n",
            " 멀지 않은 앞쪽에 햇빛이 눈부시게 내리붓고 있었다\n",
            " 도랑 있는 곳까지 와 보니, 엄청나게 물이 불어 있었다\n",
            " 빛마저 제법 붉은 흙탕물이었다\n",
            " 뛰어 건널 수가 없었다\n",
            "소년이 등을 돌려 댔다\n",
            " 소녀가 순순히 업히었다\n",
            " 걷어올린 소년의 잠방이까지 물이 올라왔다\n",
            " 소녀는 어머나’소리를 지르며 소년의 목을 끌어안았다\n",
            "개울가에 다다르기 전에, 가을 하늘이 언제 그랬는가 싶게 구름 한 점 없이 쪽빛으로 개어 있었다\n",
            "그 뒤로 소녀의 모습은 뵈지 않았다\n",
            " 매일같이 개울가로 달려와 봐도 뵈지 않았다\n",
            "학교에서 쉬는 시간에 운동장을 살피기도 했다\n",
            " 남 몰래 5학년 여자 반을 엿보기도 했다\n",
            " 그러나, 뵈지 않았다\n",
            "그날도 소년은 주머니 속 흰 조약돌만 만지작거리며 개울가로 나왔다\n",
            " 그랬더니, 이쪽 개울 뚝에 소녀가 앉아 있는 게 아닌가\n",
            "소년은 가슴부터 두근거렸다\n",
            "그동안 앓았다\n",
            "어쩐지 소녀의 얼굴이 해쓱해져 있었다\n",
            "그날, 소나기 맞은 탓 아냐?소녀가 가만히 고개를 끄덕이었다\n",
            "인제 다 났냐?아직도……\n",
            "그럼, 누워 있어야지\n",
            "하도 갑갑해서 나왔다\n",
            " ……참, 그날 재밌었어……\n",
            " 그런데 그날 어디서 이런 물이 들었는지 잘 지지 않는다\n",
            "소녀가 분홍 스웨터 앞자락을 내려다본다\n",
            " 거기에 검붉은 진흙물 같은 게 들어 있었다\n",
            "소녀가 가만히 보조개를 떠올리며,그래 이게 무슨 물 같니?소년은 스웨터 앞자락만 바라보고 있었다\n",
            "내, 생각해 냈다\n",
            " 그날, 도랑을 건너면서 내가 업힌 일이 있지? 그때, 네 등에서 옮은 물이다\n",
            "소년은 얼굴이 확 달아오름을 느꼈다\n",
            "갈림길에서 소녀는저, 오늘 아침에 우리 집에서 대추를 땄다\n",
            " 낼 제사 지내려고……\n",
            "대추 한 줌을 내준다\n",
            " 소년은 주춤한다\n",
            "맛봐라\n",
            " 우리 증조(曾祖) 할아버지가 심었다는데, 아주 달다\n",
            "소년은 두 손을 오그려 내밀며,참, 알도 굵다!그리고 저, 우리 이번에 제사 지내고 나서 좀 있다\n",
            " 집을 내주게 됐다\n",
            "소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서, 윤 초시 손자(孫子)가 서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다\n",
            " 그것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다\n",
            "왜 그런지 난 이사 가는 게 싫어졌다\n",
            " 어른들이 하는 일이니 어쩔 수 없지만……\n",
            "전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다\n",
            "소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로, 소녀가 이사를 간다는 말을 수없이 되뇌어 보았다\n",
            " 무어 그리 안타까울 것도 서러울 것도 없었다\n",
            " 그렇건만, 소년은 지금 자기가 씹고 있는 대추알의 단맛을 모르고 있었다\n",
            "이 날 밤, 소년은 몰래 떡쇠 할아버지네 호두 밭으로 갔다\n",
            "낯에 봐 두었던 나무로 올라갔다\n",
            " 그리고, 봐 두었던 가지를 향해 작대기를 내리쳤다\n",
            " 호두 송이 떨어지는 소리가 별나게 크게 들렸다\n",
            " 가슴이 선뜩했다\n",
            " 그러나 다음 순간, 굵은 호두야 많이 떨어져라, 많이 떨어져라, 저도 모를 힘에 이끌려 마구 작대기를 내리치는 것이었다\n",
            "돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다\n",
            " 그늘의 고마움을 처음 느꼈다\n",
            "불룩한 주머니를 어루만졌다\n",
            " 호두 송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아무렇지도 않았다\n",
            " 그저 근동에서 제일 가는 이 떡쇠 할아버지네 호두를 어서 소녀에게 맛 보여야 한다는 생각만이 앞섰다\n",
            "그러다, 아차 하는 생각이 들었다\n",
            " 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울가로 나와 달라는 말을 못 해 둔 것이었다\n",
            " 바보 같은 것, 바보 같은 것\n",
            "이튿날, 소년이 학교에서 돌아오니, 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 있었다\n",
            "어디 가시느냐고 물었다\n",
            "그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서,이만하면 될까?어머니가 망태기를 내주며,벌써 며칠째 걀걀’하고 알 날 자리를 보던데요\n",
            " 크진 않아도 살은 쪘을 거여요\n",
            "소년이 이번에는 어머니한테 아버지가 어디 가시느냐고 물어보았다\n",
            "저, 서당골 윤 초시 댁에 가신다\n",
            " 제사상에라도 놓으시라고……\n",
            "그럼, 큰 놈으로 하나 가져가지\n",
            " 저 얼룩 수탉으로……\n",
            "이 말에, 아버지는 허허 웃고 나서,\"인마, 그래도 이게 실속이 있다\n",
            "소년은 공연히 열적어, 책 보를 집어던지고는 외양간으로 가, 쇠잔 등을 한 번 철썩 갈겼다\n",
            " 쇠파리라도 잡는 체\n",
            "개울물은 날로 여물어 갔다\n",
            "소년은 갈림길에서 아래쪽으로 가 보았다\n",
            " 갈밭머리에서 바라보는 서당골 마을은 쪽빛 하늘 아래 한결 가까워 보였다\n",
            "어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다\n",
            " 거기 가서는 조그마한 가겟방을 비게 되리라는 것이었다\n",
            "소년은 저도 모르게 주머니 속 호두 알을 만지작거리며, 한 손으로는 수없이 갈꽃을 휘어 꺾고 있었다\n",
            "그날 밤, 소년은 자리에 누워서도 같은 생각뿐이었다\n",
            " 내일 소녀네가 이사하는 걸 가 보나 어쩌나\n",
            " 가면 소녀를 보게 될까 어떨까\n",
            "그러다가 까무룩 잠이 들었는가 하는데,허, 참 세상일도……\n",
            "마을 갔던 아버지가 언제 돌아왔는지,윤 초시 댁도 말이 아니야, 그 많던 전답을 다 팔아 버리고, 대대로 살아오던 집마저 남의 손에 넘기더니, 또 악상까지 당하는 걸 보면……\n",
            "남폿불 밑에서 바느질감을 안고 있던 어머니가,증손(曾孫)이라곤 계집애 그 애 하나뿐이었지요?그렇지, 사내 애 둘 있던 건 어려서 잃어버리고……\n",
            "어쩌면 그렇게 자식복이 없을까\n",
            "글쎄 말이지\n",
            " 이번 앤 꽤 여러 날 앓는 걸 약도 변변히 못써 봤다더군\n",
            " 지금 같아서 윤 초시네도 대가 끊긴 셈이지\n",
            " ……그런데 참, 이번 계집애 어린 것이 여간 잔망스럽지가 않아\n",
            " 글쎄, 죽기 전에 이런 말을 했다지 않아? 자기가 죽거든 자기 입던 옷을 꼭 그대로 입혀서 묻어 달라고……\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Char-RNN : https://jin-z.tistory.com/5\n",
        "\n",
        "주의 : tensorflow 재설치를 통해 버전을 변경함"
      ],
      "metadata": {
        "id": "EoV5Yjy_BxmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/solaris33/char-rnn-tensorflow.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDVDAkCiB1Q_",
        "outputId": "b4054b78-1c39-4ca8-e876-50aaeaa4e94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'char-rnn-tensorflow'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "BFi8IecZDJyk",
        "outputId": "2866ef00-450f-467c-ad4a-0969ddfb0aeb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.14 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1wClxgZ-DNCk",
        "outputId": "4b5cbcf5-62dc-4d78-b1f1-1ab66bef5d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.8.2+zzzcolab20220527125636.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? \n",
            "Your response ('') was not one of the expected responses: y, n\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 41 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.21.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 62.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.46.3)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd char-rnn-tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwNCExJ7FWjp",
        "outputId": "84ce8522-2b8d-4513-e8da-5ebece74cd67"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/char-rnn-tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnoloUtLB9is",
        "outputId": "44dbd212-dc17-4546-fd7b-fb70d749765c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "loading preprocessed files\n",
            "WARNING:tensorflow:From train.py:32: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:38: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:44: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From train.py:48: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From train.py:60: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6f263cea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6f263cea50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6f267c95d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6f267c95d0>>: AttributeError: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6f25a92f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6f25a92f10>>: AttributeError: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From train.py:70: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From train.py:74: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From train.py:76: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:80: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-07-09 03:51:34.392049: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-07-09 03:51:34.399027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200210000 Hz\n",
            "2022-07-09 03:51:34.399373: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26d3800 executing computations on platform Host. Devices:\n",
            "2022-07-09 03:51:34.399417: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "WARNING:tensorflow:From train.py:82: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2022-07-09 03:51:34.457082: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "0(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 4.835\n",
            "1(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 4.234\n",
            "2(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 4.025\n",
            "3(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.814\n",
            "4(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.501\n",
            "5(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.554\n",
            "6(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.418\n",
            "7(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.354\n",
            "8(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.263\n",
            "9(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.253\n",
            "10(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.192\n",
            "11(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.191\n",
            "12(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.131\n",
            "13(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.114\n",
            "14(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.079\n",
            "15(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.035\n",
            "16(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.033\n",
            "17(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 3.001\n",
            "18(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.954\n",
            "19(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.955\n",
            "20(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.942\n",
            "21(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.946\n",
            "22(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.914\n",
            "23(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.898\n",
            "24(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.847\n",
            "25(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.864\n",
            "26(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.800\n",
            "27(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.802\n",
            "28(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.738\n",
            "29(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.750\n",
            "30(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.777\n",
            "31(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.786\n",
            "32(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.667\n",
            "33(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.668\n",
            "34(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.647\n",
            "35(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.655\n",
            "36(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.718\n",
            "37(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.642\n",
            "38(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.609\n",
            "39(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.595\n",
            "40(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.638\n",
            "41(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.576\n",
            "42(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.532\n",
            "43(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.472\n",
            "44(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.548\n",
            "45(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.489\n",
            "46(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.447\n",
            "47(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.488\n",
            "48(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.470\n",
            "49(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.444\n",
            "50(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.446\n",
            "51(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.394\n",
            "52(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.410\n",
            "53(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.434\n",
            "54(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.391\n",
            "55(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.384\n",
            "56(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.335\n",
            "57(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.353\n",
            "58(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.324\n",
            "59(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.308\n",
            "60(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.375\n",
            "61(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.383\n",
            "62(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.316\n",
            "63(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.357\n",
            "64(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.298\n",
            "65(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.301\n",
            "66(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.290\n",
            "67(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.279\n",
            "68(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.301\n",
            "69(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.290\n",
            "70(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.254\n",
            "71(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.268\n",
            "72(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.254\n",
            "73(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.193\n",
            "74(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.217\n",
            "75(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.215\n",
            "76(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.209\n",
            "77(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.242\n",
            "78(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.240\n",
            "79(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.208\n",
            "80(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.253\n",
            "81(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.121\n",
            "82(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.179\n",
            "83(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.171\n",
            "84(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.198\n",
            "85(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.151\n",
            "86(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.132\n",
            "87(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.094\n",
            "88(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.215\n",
            "89(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.104\n",
            "90(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.107\n",
            "91(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.093\n",
            "92(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.112\n",
            "93(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.114\n",
            "94(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.165\n",
            "95(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.157\n",
            "96(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.146\n",
            "97(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.096\n",
            "98(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.068\n",
            "99(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.137\n",
            "100(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.086\n",
            "101(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.080\n",
            "102(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.110\n",
            "103(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.074\n",
            "104(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.073\n",
            "105(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.078\n",
            "106(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.043\n",
            "107(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.079\n",
            "108(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.080\n",
            "109(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.006\n",
            "110(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.991\n",
            "111(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.075\n",
            "112(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.058\n",
            "113(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.044\n",
            "114(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.085\n",
            "115(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.071\n",
            "116(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.049\n",
            "117(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.074\n",
            "118(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.022\n",
            "119(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.956\n",
            "120(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.013\n",
            "121(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.026\n",
            "122(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.980\n",
            "123(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.976\n",
            "124(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.030\n",
            "125(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.061\n",
            "126(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.980\n",
            "127(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.015\n",
            "128(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.043\n",
            "129(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.946\n",
            "130(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.940\n",
            "131(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.990\n",
            "132(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.039\n",
            "133(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.975\n",
            "134(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.952\n",
            "135(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.018\n",
            "136(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.000\n",
            "137(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.024\n",
            "138(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.009\n",
            "139(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.054\n",
            "140(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.032\n",
            "141(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.000\n",
            "142(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.933\n",
            "143(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.959\n",
            "144(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.968\n",
            "145(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.982\n",
            "146(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.946\n",
            "147(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.920\n",
            "148(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.974\n",
            "149(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.991\n",
            "150(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.915\n",
            "151(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.978\n",
            "152(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.942\n",
            "153(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.947\n",
            "154(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.939\n",
            "155(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.957\n",
            "156(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.919\n",
            "157(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.942\n",
            "158(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.934\n",
            "159(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.940\n",
            "160(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.904\n",
            "161(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 2.018\n",
            "162(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.950\n",
            "163(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.923\n",
            "164(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.970\n",
            "165(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.952\n",
            "166(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.904\n",
            "167(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.844\n",
            "168(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.918\n",
            "169(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.947\n",
            "170(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.944\n",
            "171(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.959\n",
            "172(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.921\n",
            "173(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.896\n",
            "174(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.946\n",
            "175(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.969\n",
            "176(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.925\n",
            "177(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.866\n",
            "178(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.846\n",
            "179(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.851\n",
            "180(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.886\n",
            "181(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.918\n",
            "182(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.928\n",
            "183(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.911\n",
            "184(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.784\n",
            "185(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.867\n",
            "186(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.872\n",
            "187(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.919\n",
            "188(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.892\n",
            "189(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.824\n",
            "190(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.888\n",
            "191(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.792\n",
            "192(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.862\n",
            "193(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.864\n",
            "194(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.900\n",
            "195(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.847\n",
            "196(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.838\n",
            "197(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.904\n",
            "198(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.915\n",
            "199(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.895\n",
            "200(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.898\n",
            "201(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.878\n",
            "202(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.905\n",
            "203(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.848\n",
            "204(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.872\n",
            "205(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.870\n",
            "206(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.869\n",
            "207(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.899\n",
            "208(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.920\n",
            "209(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.846\n",
            "210(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.874\n",
            "211(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.818\n",
            "212(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.855\n",
            "213(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.877\n",
            "214(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.779\n",
            "215(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.843\n",
            "216(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.862\n",
            "217(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.845\n",
            "218(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.810\n",
            "219(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.837\n",
            "220(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.836\n",
            "221(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.884\n",
            "222(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.860\n",
            "223(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.824\n",
            "224(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.806\n",
            "225(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.798\n",
            "226(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.905\n",
            "227(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.845\n",
            "228(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.848\n",
            "229(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.865\n",
            "230(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.872\n",
            "231(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.840\n",
            "232(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.829\n",
            "233(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.874\n",
            "234(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.840\n",
            "235(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.821\n",
            "236(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.811\n",
            "237(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.797\n",
            "238(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.818\n",
            "239(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.810\n",
            "240(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.830\n",
            "241(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.778\n",
            "242(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.799\n",
            "243(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.837\n",
            "244(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.761\n",
            "245(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.783\n",
            "246(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.822\n",
            "247(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.808\n",
            "248(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.854\n",
            "249(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.762\n",
            "250(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.834\n",
            "251(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.744\n",
            "252(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.824\n",
            "253(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.772\n",
            "254(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.819\n",
            "255(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.807\n",
            "256(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.756\n",
            "257(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.773\n",
            "258(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.804\n",
            "259(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.768\n",
            "260(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.748\n",
            "261(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.765\n",
            "262(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.766\n",
            "263(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.778\n",
            "264(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.724\n",
            "265(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.825\n",
            "266(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.837\n",
            "267(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.788\n",
            "268(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.767\n",
            "269(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.765\n",
            "270(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.779\n",
            "271(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.820\n",
            "272(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.717\n",
            "273(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.808\n",
            "274(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.792\n",
            "275(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.813\n",
            "276(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.751\n",
            "277(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.798\n",
            "278(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.784\n",
            "279(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.805\n",
            "280(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.758\n",
            "281(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.817\n",
            "282(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.768\n",
            "283(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.741\n",
            "284(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.764\n",
            "285(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.750\n",
            "286(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.739\n",
            "287(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.794\n",
            "288(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.810\n",
            "289(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.748\n",
            "290(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.753\n",
            "291(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.762\n",
            "292(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.740\n",
            "293(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.776\n",
            "294(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.782\n",
            "295(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.765\n",
            "296(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.774\n",
            "297(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.709\n",
            "298(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.814\n",
            "299(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.692\n",
            "300(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.674\n",
            "301(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.745\n",
            "302(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.682\n",
            "303(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.662\n",
            "304(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.783\n",
            "305(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.752\n",
            "306(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.680\n",
            "307(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.760\n",
            "308(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.778\n",
            "309(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.744\n",
            "310(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.710\n",
            "311(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.798\n",
            "312(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.765\n",
            "313(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.784\n",
            "314(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.686\n",
            "315(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.734\n",
            "316(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.733\n",
            "317(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.744\n",
            "318(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.726\n",
            "319(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.689\n",
            "320(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.705\n",
            "321(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.721\n",
            "322(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.718\n",
            "323(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.682\n",
            "324(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.726\n",
            "325(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.717\n",
            "326(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.711\n",
            "327(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.693\n",
            "328(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.744\n",
            "329(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.685\n",
            "330(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.689\n",
            "331(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.757\n",
            "332(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.696\n",
            "333(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.633\n",
            "334(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.695\n",
            "335(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.693\n",
            "336(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.721\n",
            "337(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.730\n",
            "338(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.806\n",
            "339(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.664\n",
            "340(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.737\n",
            "341(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.631\n",
            "342(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.716\n",
            "343(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.724\n",
            "344(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.638\n",
            "345(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.720\n",
            "346(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.669\n",
            "347(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.753\n",
            "348(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.679\n",
            "349(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.785\n",
            "350(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.753\n",
            "351(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.692\n",
            "352(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.647\n",
            "353(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.639\n",
            "354(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.637\n",
            "355(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.713\n",
            "356(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.750\n",
            "357(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.743\n",
            "358(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.653\n",
            "359(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.668\n",
            "360(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.726\n",
            "361(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.662\n",
            "362(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.667\n",
            "363(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.736\n",
            "364(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.721\n",
            "365(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.676\n",
            "366(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.676\n",
            "367(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.652\n",
            "368(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.687\n",
            "369(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.682\n",
            "370(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.820\n",
            "371(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.683\n",
            "372(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.722\n",
            "373(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.705\n",
            "374(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.709\n",
            "375(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.691\n",
            "376(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.702\n",
            "377(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.674\n",
            "378(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.683\n",
            "379(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.666\n",
            "380(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.716\n",
            "381(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.695\n",
            "382(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.748\n",
            "383(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.691\n",
            "384(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.692\n",
            "385(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.747\n",
            "386(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.710\n",
            "387(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.715\n",
            "388(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.741\n",
            "389(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.660\n",
            "390(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.686\n",
            "391(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.699\n",
            "392(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.679\n",
            "393(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.720\n",
            "394(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.650\n",
            "395(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.712\n",
            "396(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.662\n",
            "397(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.615\n",
            "398(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.687\n",
            "399(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.646\n",
            "400(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.705\n",
            "401(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.708\n",
            "402(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.679\n",
            "403(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.719\n",
            "404(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.697\n",
            "405(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.698\n",
            "406(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.708\n",
            "407(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.661\n",
            "408(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.731\n",
            "409(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.689\n",
            "410(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.707\n",
            "411(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.649\n",
            "412(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.681\n",
            "413(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.641\n",
            "414(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.663\n",
            "415(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.677\n",
            "416(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.663\n",
            "417(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.641\n",
            "418(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.644\n",
            "419(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.712\n",
            "420(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.676\n",
            "421(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.697\n",
            "422(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.708\n",
            "423(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.711\n",
            "424(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.683\n",
            "425(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.654\n",
            "426(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.728\n",
            "427(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.668\n",
            "428(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.668\n",
            "429(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.698\n",
            "430(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.617\n",
            "431(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.742\n",
            "432(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.647\n",
            "433(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.676\n",
            "434(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.663\n",
            "435(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.657\n",
            "436(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.679\n",
            "437(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.652\n",
            "438(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.762\n",
            "439(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.633\n",
            "440(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.682\n",
            "441(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.592\n",
            "442(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.616\n",
            "443(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.593\n",
            "444(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.651\n",
            "445(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 1.642\n",
            "446(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.796\n",
            "447(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.645\n",
            "448(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.649\n",
            "449(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.639\n",
            "450(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.694\n",
            "451(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.681\n",
            "452(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.682\n",
            "453(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.686\n",
            "454(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.615\n",
            "455(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.561\n",
            "456(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.715\n",
            "457(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "458(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.652\n",
            "459(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.629\n",
            "460(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "461(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.629\n",
            "462(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.689\n",
            "463(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.604\n",
            "464(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.618\n",
            "465(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.635\n",
            "466(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.559\n",
            "467(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.609\n",
            "468(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.580\n",
            "469(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.608\n",
            "470(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.550\n",
            "471(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.609\n",
            "472(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.590\n",
            "473(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.603\n",
            "474(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.645\n",
            "475(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.639\n",
            "476(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.638\n",
            "477(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.657\n",
            "478(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.612\n",
            "479(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.627\n",
            "480(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.668\n",
            "481(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.611\n",
            "482(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.759\n",
            "483(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.719\n",
            "484(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.660\n",
            "485(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.680\n",
            "486(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.691\n",
            "487(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.694\n",
            "488(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.613\n",
            "489(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.609\n",
            "490(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.683\n",
            "491(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.645\n",
            "492(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.591\n",
            "493(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.588\n",
            "494(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.619\n",
            "495(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.574\n",
            "496(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "497(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.566\n",
            "498(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.592\n",
            "499(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.637\n",
            "500(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.632\n",
            "501(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.610\n",
            "502(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.567\n",
            "503(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.646\n",
            "504(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.616\n",
            "505(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.609\n",
            "506(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.676\n",
            "507(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.632\n",
            "508(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.626\n",
            "509(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.656\n",
            "510(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.590\n",
            "511(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.642\n",
            "512(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.590\n",
            "513(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.664\n",
            "514(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.671\n",
            "515(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.638\n",
            "516(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.629\n",
            "517(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.592\n",
            "518(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.651\n",
            "519(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.581\n",
            "520(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.574\n",
            "521(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.638\n",
            "522(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.647\n",
            "523(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.648\n",
            "524(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.624\n",
            "525(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.670\n",
            "526(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.621\n",
            "527(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.508\n",
            "528(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.582\n",
            "529(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.615\n",
            "530(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.630\n",
            "531(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.641\n",
            "532(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.581\n",
            "533(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.561\n",
            "534(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.681\n",
            "535(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.597\n",
            "536(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.558\n",
            "537(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.577\n",
            "538(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.618\n",
            "539(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.587\n",
            "540(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.608\n",
            "541(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.667\n",
            "542(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.627\n",
            "543(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.622\n",
            "544(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.533\n",
            "545(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.670\n",
            "546(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.557\n",
            "547(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.613\n",
            "548(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.627\n",
            "549(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.570\n",
            "550(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.611\n",
            "551(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.607\n",
            "552(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.580\n",
            "553(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.606\n",
            "554(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.629\n",
            "555(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.542\n",
            "556(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.519\n",
            "557(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.574\n",
            "558(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.622\n",
            "559(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.600\n",
            "560(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.613\n",
            "561(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.630\n",
            "562(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.592\n",
            "563(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.646\n",
            "564(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.626\n",
            "565(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.523\n",
            "566(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.622\n",
            "567(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.617\n",
            "568(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.559\n",
            "569(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.583\n",
            "570(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.614\n",
            "571(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.646\n",
            "572(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.594\n",
            "573(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.618\n",
            "574(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.640\n",
            "575(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.560\n",
            "576(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.505\n",
            "577(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.605\n",
            "578(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.638\n",
            "579(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "580(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.583\n",
            "581(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.647\n",
            "582(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.642\n",
            "583(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.668\n",
            "584(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.629\n",
            "585(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.637\n",
            "586(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.626\n",
            "587(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.635\n",
            "588(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.538\n",
            "589(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.571\n",
            "590(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.593\n",
            "591(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.615\n",
            "592(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.571\n",
            "593(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.564\n",
            "594(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.587\n",
            "595(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.575\n",
            "596(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.530\n",
            "597(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.615\n",
            "598(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.591\n",
            "599(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.577\n",
            "600(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.594\n",
            "601(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.601\n",
            "602(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.591\n",
            "603(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.602\n",
            "604(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.624\n",
            "605(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "606(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.590\n",
            "607(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.710\n",
            "608(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.627\n",
            "609(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.609\n",
            "610(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.648\n",
            "611(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.591\n",
            "612(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.561\n",
            "613(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.520\n",
            "614(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.611\n",
            "615(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.645\n",
            "616(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.618\n",
            "617(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.609\n",
            "618(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.621\n",
            "619(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.580\n",
            "620(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.604\n",
            "621(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.630\n",
            "622(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.603\n",
            "623(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.572\n",
            "624(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.523\n",
            "625(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.565\n",
            "626(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.572\n",
            "627(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.563\n",
            "628(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.604\n",
            "629(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.581\n",
            "630(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.485\n",
            "631(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.541\n",
            "632(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.582\n",
            "633(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.590\n",
            "634(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.583\n",
            "635(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.512\n",
            "636(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "637(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.494\n",
            "638(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.549\n",
            "639(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.601\n",
            "640(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.603\n",
            "641(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.510\n",
            "642(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.521\n",
            "643(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.586\n",
            "644(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.611\n",
            "645(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.617\n",
            "646(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.635\n",
            "647(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.580\n",
            "648(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.600\n",
            "649(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.513\n",
            "650(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.535\n",
            "651(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.597\n",
            "652(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.593\n",
            "653(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.609\n",
            "654(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.646\n",
            "655(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.571\n",
            "656(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.568\n",
            "657(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.535\n",
            "658(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.571\n",
            "659(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.570\n",
            "660(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.527\n",
            "661(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.547\n",
            "662(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.556\n",
            "663(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.548\n",
            "664(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.539\n",
            "665(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.563\n",
            "666(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.570\n",
            "667(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.588\n",
            "668(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.595\n",
            "669(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.555\n",
            "670(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.538\n",
            "671(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.536\n",
            "672(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.614\n",
            "673(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.584\n",
            "674(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.600\n",
            "675(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.599\n",
            "676(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.625\n",
            "677(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.584\n",
            "678(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.590\n",
            "679(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.618\n",
            "680(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.606\n",
            "681(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.561\n",
            "682(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.592\n",
            "683(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.539\n",
            "684(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.573\n",
            "685(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.576\n",
            "686(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.566\n",
            "687(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.546\n",
            "688(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.536\n",
            "689(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.564\n",
            "690(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.511\n",
            "691(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.554\n",
            "692(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.576\n",
            "693(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.543\n",
            "694(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.613\n",
            "695(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.544\n",
            "696(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.590\n",
            "697(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.504\n",
            "698(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.600\n",
            "699(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.529\n",
            "700(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.557\n",
            "701(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.563\n",
            "702(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.512\n",
            "703(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.561\n",
            "704(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.552\n",
            "705(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.536\n",
            "706(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.511\n",
            "707(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.545\n",
            "708(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.518\n",
            "709(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.549\n",
            "710(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.515\n",
            "711(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.608\n",
            "712(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.603\n",
            "713(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.577\n",
            "714(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.539\n",
            "715(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.535\n",
            "716(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.548\n",
            "717(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.575\n",
            "718(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.500\n",
            "719(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.594\n",
            "720(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.577\n",
            "721(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.608\n",
            "722(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.548\n",
            "723(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.582\n",
            "724(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.570\n",
            "725(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.576\n",
            "726(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.538\n",
            "727(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.589\n",
            "728(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.545\n",
            "729(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.509\n",
            "730(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.563\n",
            "731(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.535\n",
            "732(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.505\n",
            "733(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.587\n",
            "734(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.611\n",
            "735(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.557\n",
            "736(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.526\n",
            "737(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.532\n",
            "738(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.548\n",
            "739(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.559\n",
            "740(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.557\n",
            "741(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.587\n",
            "742(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.563\n",
            "743(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.512\n",
            "744(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.604\n",
            "745(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.510\n",
            "746(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.502\n",
            "747(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.562\n",
            "748(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.503\n",
            "749(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.474\n",
            "750(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.580\n",
            "751(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.558\n",
            "752(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.489\n",
            "753(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.562\n",
            "754(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.605\n",
            "755(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.565\n",
            "756(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.525\n",
            "757(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "758(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.594\n",
            "759(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.606\n",
            "760(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.511\n",
            "761(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.529\n",
            "762(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.549\n",
            "763(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.546\n",
            "764(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.522\n",
            "765(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.475\n",
            "766(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.505\n",
            "767(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.534\n",
            "768(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.530\n",
            "769(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.498\n",
            "770(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.539\n",
            "771(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.529\n",
            "772(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.542\n",
            "773(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.504\n",
            "774(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.564\n",
            "775(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.497\n",
            "776(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.493\n",
            "777(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.569\n",
            "778(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.508\n",
            "779(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.437\n",
            "780(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.513\n",
            "781(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.520\n",
            "782(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.539\n",
            "783(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.526\n",
            "784(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.614\n",
            "785(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.508\n",
            "786(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.570\n",
            "787(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.467\n",
            "788(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.541\n",
            "789(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.548\n",
            "790(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.456\n",
            "791(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.532\n",
            "792(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.502\n",
            "793(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.574\n",
            "794(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.512\n",
            "795(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.633\n",
            "796(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.565\n",
            "797(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.548\n",
            "798(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.467\n",
            "799(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.507\n",
            "800(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.483\n",
            "801(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.514\n",
            "802(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.570\n",
            "803(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "804(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.490\n",
            "805(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.516\n",
            "806(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.563\n",
            "807(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.512\n",
            "808(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.501\n",
            "809(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.554\n",
            "810(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.555\n",
            "811(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.505\n",
            "812(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.480\n",
            "813(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.479\n",
            "814(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.527\n",
            "815(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.511\n",
            "816(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.617\n",
            "817(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.495\n",
            "818(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.556\n",
            "819(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.530\n",
            "820(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.553\n",
            "821(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.522\n",
            "822(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.534\n",
            "823(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.499\n",
            "824(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.516\n",
            "825(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.500\n",
            "826(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.547\n",
            "827(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.521\n",
            "828(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.584\n",
            "829(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.525\n",
            "830(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.532\n",
            "831(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.582\n",
            "832(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.530\n",
            "833(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.571\n",
            "834(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.569\n",
            "835(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.495\n",
            "836(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.522\n",
            "837(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.539\n",
            "838(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.510\n",
            "839(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.567\n",
            "840(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.486\n",
            "841(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.549\n",
            "842(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.492\n",
            "843(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.452\n",
            "844(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.531\n",
            "845(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.494\n",
            "846(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.545\n",
            "847(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.548\n",
            "848(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.525\n",
            "849(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.557\n",
            "850(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.522\n",
            "851(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.539\n",
            "852(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.546\n",
            "853(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.509\n",
            "854(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.566\n",
            "855(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.545\n",
            "856(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.553\n",
            "857(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.504\n",
            "858(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.527\n",
            "859(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.477\n",
            "860(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.499\n",
            "861(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.518\n",
            "862(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.521\n",
            "863(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.506\n",
            "864(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.500\n",
            "865(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.545\n",
            "866(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.525\n",
            "867(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.557\n",
            "868(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.566\n",
            "869(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.555\n",
            "870(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.532\n",
            "871(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.506\n",
            "872(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.570\n",
            "873(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.523\n",
            "874(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.504\n",
            "875(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.544\n",
            "876(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.485\n",
            "877(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.598\n",
            "878(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.495\n",
            "879(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.533\n",
            "880(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.509\n",
            "881(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.502\n",
            "882(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.518\n",
            "883(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.508\n",
            "884(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.638\n",
            "885(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.499\n",
            "886(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.540\n",
            "887(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.461\n",
            "888(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.486\n",
            "889(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.466\n",
            "890(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.517\n",
            "891(학습한 배치개수)/892(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 1.492\n",
            "트레이닝이 끝났습니다!\n",
            "샘플링을 시작합니다!\n",
            "샘플링 결과:\n",
            " make,\n",
            "Be might selves o' your wrest Wars mindes; I was it.\n",
            "\n",
            "ESCALUS:\n",
            "How very my handle done? Luceindioned,\n",
            "And such pail-thing the hearth, inlove; the diwn;\n",
            "That loye blood of shall he sweet his litth.\n",
            "\n",
            "LUCIO:\n",
            "Where have knowen thysefore mind so.\n",
            "\n",
            "Five:\n",
            "Lew not pery by the acturition.\n",
            "\n",
            "Second Watcher:\n",
            "And precy his hour, burink the confeingents,\n",
            "Some for somerly, he trick him!\n",
            "\n",
            "LORIS:\n",
            "If I cansciant hit evenge in: have him to carmel,\n",
            "Evenners in eyer on as not it a wife,\n",
            "And they glaw the fathed they but come, thence?\n",
            "\n",
            "First Mursir;\n",
            "Allow, or Isa indenession channow\n",
            "Death's life; rethe thee forceive on way the man, Here\n",
            "thee, wike, his hers spies! and rever's staple,--\n",
            "\n",
            "VINGsRY I:\n",
            "I shen is he spare upon thee good,\n",
            "If resce hive so her be high if;\n",
            "Of before this ca redains! from me, Vonce,\n",
            "And is the quarders in afrest I will read's''s king's news.\n",
            "Ay, who, the hands they up, here love his prince,\n",
            "Thou, quil be busictions;'\n",
            "And to your locking the hea,\n",
            "Ho! them, the came and ighne; the had one  the scondember:\n",
            "Some not worn him, go, he is your hears\n",
            "Whereince to mather with me thee sight aoul\n",
            "To found sir, I must our horey; this shun not Duke,\n",
            "And let could he! kill-vist suppose as young to.\n",
            "Kouserio, heaven, sir?\n",
            "\n",
            "ANGELO:\n",
            "No, my aborn: I will coes the shight how I child;\n",
            "And the imput to this is renegter? What thou a sprinks:\n",
            "Goody, bith to his have, nor direver passion.\n",
            "Sir I dold they all thy word; with with now I seens.\n",
            "A know show no let wreason; he I have ramon,?\n",
            "\n",
            "Polsce:\n",
            "That hepher that are may beday Tower death.\n",
            "\n",
            "Provost:\n",
            "CEmistepcy, enemy mine more the death: for mine envernice,\n",
            "And blids eyes might 'boke her very since, lieves' reage;\n",
            "And which not the would heaven so night, whire's knows;\n",
            "By heir our Englangs am commond, here?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "To have tings awing to begive Clirance,\n",
            "In thy aloedies you never me in him?\n",
            "\n",
            "ODWARLIO:\n",
            "How not, swick loves , bear deain-duataunt,\n",
            "And companty, my more o'er thee pliness,\n",
            "This cove the nave show he\n",
            "plicing saven rencher pressessess and so for enever her;\n",
            "To night his more that Trays!\n",
            "And have strived? me the hirds's no the defersemen,\n",
            "By my gearle! you love ay the king follow.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "O, before I her now,' or.\n",
            "\n",
            "BONIOLINES:\n",
            "O, for his still this sear me to say of taxping,\n",
            "Which seeming his teep I shall this presongrafe\n",
            "But no justice blow come, High as chilfesses offers:\n",
            "I am listres, that stay no? I have black your dram?\n",
            "\n",
            "TRANIO:\n",
            "Consent, bids, Warwick us weep's alonger.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "'Twas now, anger; countray's here's,\n",
            "Which bett should Crany's suchlers your gind\n",
            "That stristh and under swear theer I prince, still\n",
            "And it of my wrack'd when usanchful for her worse,\n",
            "How Naller in his part Midound of his of\n",
            "weect of so brother lords with us.\n",
            "\n",
            "AUTOLYCUS:\n",
            "I sir? Cludionours, me stain-god heavenant,\n",
            "But not me I come eneven-a too.\n",
            "\n",
            "KING RICHARD III:\n",
            "I come, the vengeal the nect do him?\n",
            "\n",
            "RICHARD:\n",
            "The trub; you merriage his is the sower; she chand.\n",
            "\n",
            "GLOUCESTES:\n",
            "Beinguard them, my for So nor Edward's Appason.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "But our viliox them heaven you withings\n",
            "The leasting-greatered, Warwick at thou thy depost\n",
            "Dodes saist meling the misiffor the man her.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Ay, I vieutediing so, but he caste.\n",
            "\n",
            "KING RICHARD III:\n",
            "Aft nu friends. be the off to\n",
            "incon the say too't; unto thee, bouses,\n",
            "That, those vengeleo.\n",
            "Thou crest of the prayers could now.\n",
            "\n",
            "Clown the sun quarce, see:\n",
            "Under dreen by outs that given's it sleep, baste;\n",
            "And else 't her is execute to meet man\n",
            "\n",
            "Pecase's me he hather very them, I will know'd,\n",
            "I meant thy snelquences and spiejies: we showes\n",
            "Of your heart's some thunes on or fr all.\n",
            "\n",
            "KING RICHARD III:\n",
            "By the weepher he sell of mirreds, given,\n",
            "In that my graen these their hamentss tongue weep!\n",
            "Therefor me meet of them, have them?\n",
            "That eyes are aither from the tread's trains no hears.\n",
            "I vease and prince that lies unchape?\n",
            "\n",
            "First LaUN. Lord:\n",
            "She have muschers pressiong's patiens.\n",
            "\n",
            "CORIO:\n",
            "Of my Laxure us an house; not for I'l,\n",
            "Brozed, here, not the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zg8hfjX7FU8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import os\n",
        "import collections\n",
        "from six.moves import cPickle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TextLoader():\n",
        "    def __init__(self, data_dir, batch_size, seq_length, encoding='utf-8'):\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_length = seq_length\n",
        "        self.encoding = encoding\n",
        "\n",
        "        input_file = os.path.join(data_dir, \"input.txt\")\n",
        "        vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
        "        tensor_file = os.path.join(data_dir, \"data.npy\")\n",
        "\n",
        "        # 전처리된 파일들(\"vocab.pkl\", \"data.npy\")이 이미 존재하면 이를 불러오고 없으면 데이터 전처리를 진행합니다.\n",
        "        if not (os.path.exists(vocab_file) and os.path.exists(tensor_file)):\n",
        "            print(\"reading text file\")\n",
        "            self.preprocess(input_file, vocab_file, tensor_file)\n",
        "        else:\n",
        "            print(\"loading preprocessed files\")\n",
        "            self.load_preprocessed(vocab_file, tensor_file)\n",
        "        # 배치를 생성하고 배치 포인터를 배치의 시작지점으로 리셋합니다.\n",
        "        self.create_batches()\n",
        "        self.reset_batch_pointer()\n",
        "\n",
        "    # 데이터 전처리를 진행합니다.\n",
        "    def preprocess(self, input_file, vocab_file, tensor_file):\n",
        "        with codecs.open(input_file, \"r\", encoding=self.encoding) as f:\n",
        "            data = f.read()\n",
        "        # 데이터에서 문자(character)별 등장횟수를 셉니다.\n",
        "        counter = collections.Counter(data)\n",
        "        count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
        "        self.chars, _ = zip(*count_pairs) # 전체 문자들(Chracters)\n",
        "        self.vocab_size = len(self.chars) # 전체 문자(단어) 개수\n",
        "        self.vocab = dict(zip(self.chars, range(len(self.chars)))) # 단어들을 (charcter, id) 형태의 dictionary로 만듭니다.\n",
        "        with open(vocab_file, 'wb') as f:\n",
        "            cPickle.dump(self.chars, f)\n",
        "        # 데이터의 각각의 character들을 id로 변경합니다.\n",
        "        self.tensor = np.array(list(map(self.vocab.get, data)))\n",
        "        # id로 변경한 데이터를 \"data.npy\" binary numpy 파일로 저장힙니다.\n",
        "        np.save(tensor_file, self.tensor)\n",
        "\n",
        "    # 전처리한 데이터가 파일로 저장되어 있다면 파일로부터 전처리된 정보들을 읽어옵니다.\n",
        "    def load_preprocessed(self, vocab_file, tensor_file):\n",
        "        with open(vocab_file, 'rb') as f:\n",
        "            self.chars = cPickle.load(f)\n",
        "        self.vocab_size = len(self.chars)\n",
        "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
        "        self.tensor = np.load(tensor_file)\n",
        "        self.num_batches = int(self.tensor.size / (self.batch_size * self.seq_length))\n",
        "\n",
        "    # 전체 데이터를 배치 단위로 묶습니다.\n",
        "    def create_batches(self):\n",
        "        self.num_batches = int(self.tensor.size / (self.batch_size * self.seq_length))\n",
        "\n",
        "        # 데이터 양이 너무 적어서 1개의 배치도 만들수없을 경우, 에러 메세지를 출력합니다.\n",
        "        if self.num_batches == 0:\n",
        "            assert False, \"Not enough data. Make seq_length and batch_size small.\"\n",
        "\n",
        "        # 배치에 필요한 정수만큼의 데이터만을 불러옵니다. e.g. 1115394 -> 1115000\n",
        "        self.tensor = self.tensor[:self.num_batches * self.batch_size * self.seq_length]\n",
        "        xdata = self.tensor\n",
        "        ydata = np.copy(self.tensor)\n",
        "        # 타겟 데이터는 인풋 데이터를 한칸 뒤로 민 형태로 구성합니다.\n",
        "        ydata[:-1] = xdata[1:]\n",
        "        ydata[-1] = xdata[0]\n",
        "        # batch_size 크기의 배치를 num_batches 개수 만큼 생성합니다. \n",
        "        self.x_batches = np.split(xdata.reshape(self.batch_size, -1),\n",
        "                                  self.num_batches, 1)\n",
        "        self.y_batches = np.split(ydata.reshape(self.batch_size, -1),\n",
        "                                  self.num_batches, 1)\n",
        "\n",
        "    # 다음 배치롤 불러오고 배치 포인터를 1만큼 증가시킵니다.  \n",
        "    def next_batch(self):\n",
        "        x, y = self.x_batches[self.pointer], self.y_batches[self.pointer]\n",
        "        self.pointer += 1\n",
        "        return x, y\n",
        "\n",
        "    # 배치의 시작점을 데이터의 시작지점으로 리셋합니다.\n",
        "    def reset_batch_pointer(self):\n",
        "        self.pointer = 0"
      ],
      "metadata": {
        "id": "_GXI7C1gCBfx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_O5c_ZsHCAh",
        "outputId": "d2017313-0d56-455a-97a7-b2b75890ef18"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mchar-rnn-tensorflow\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Char-RNN 예제\n",
        "# Author : solaris33\n",
        "# Project URL : http://solarisailab.com/archives/2487\n",
        "# GitHub Repository : https://github.com/solaris33/char-rnn-tensorflow/\n",
        "# Reference : https://github.com/sherjilozair/char-rnn-tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from utils import TextLoader\n",
        "tf.reset_default_graph()\n",
        "# 학습에 필요한 설정값들을 지정합니다.\n",
        "data_dir = 'drive/MyDrive/colab_test/sonagi' # 셰익스피어 희곡 <리처드 3세> 데이터로 학습\n",
        "#data_dir = 'data/linux' # <Linux 소스코드> 데이터로 학습\n",
        "batch_size = 50 # Training : 50, Sampling : 1\n",
        "seq_length = 50 # Training : 50, Sampling : 1\n",
        "hidden_size = 128   # 히든 레이어의 노드 개수\n",
        "learning_rate = 0.002\n",
        "num_epochs = 200\n",
        "num_hidden_layers = 2\n",
        "grad_clip = 5   # Gradient Clipping에 사용할 임계값\n",
        "\n",
        "# TextLoader를 이용해서 데이터를 불러옵니다.\n",
        "data_loader = TextLoader(data_dir, batch_size, seq_length)\n",
        "# 학습데이터에 포함된 모든 단어들을 나타내는 변수인 chars와 chars에 id를 부여해 dict 형태로 만든 vocab을 선언합니다.\n",
        "chars = data_loader.chars \n",
        "vocab = data_loader.vocab\n",
        "vocab_size = data_loader.vocab_size # 전체 단어개수\n",
        "\n",
        "# 인풋데이터와 타겟데이터, 배치 사이즈를 입력받기 위한 플레이스홀더를 설정합니다.\n",
        "input_data = tf.placeholder(tf.int32, shape=[None, None])  # input_data : [batch_size, seq_length])\n",
        "target_data = tf.placeholder(tf.int32, shape=[None, None]) # target_data : [batch_size, seq_length])\n",
        "state_batch_size = tf.placeholder(tf.int32, shape=[])      # Training : 50, Sampling : 1\n",
        "\n",
        "# RNN의 마지막 히든레이어의 출력을 소프트맥스 출력값으로 변환해주기 위한 변수들을 선언합니다.\n",
        "# hidden_size -> vocab_size\n",
        "softmax_w = tf.Variable(tf.random_normal(shape=[hidden_size, vocab_size]), dtype=tf.float32)\n",
        "softmax_b = tf.Variable(tf.random_normal(shape=[vocab_size]), dtype=tf.float32)\n",
        "\n",
        "# num_hidden_layers만큼 LSTM cell(히든레이어)를 선언합니다.\n",
        "cells = []\n",
        "for _ in range(0, num_hidden_layers):\n",
        "    cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
        "    cells.append(cell)\n",
        "\n",
        "# cell을 종합해서 RNN을 정의합니다.\n",
        "cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
        "\n",
        "# 인풋데이터를 변환하기 위한 Embedding Matrix를 선언합니다.\n",
        "# vocab_size -> hidden_size\n",
        "embedding = tf.Variable(tf.random_normal(shape=[vocab_size, hidden_size]), dtype=tf.float32)\n",
        "inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
        "\n",
        "# 초기 state 값을 0으로 초기화합니다.\n",
        "initial_state = cell.zero_state(state_batch_size, tf.float32)\n",
        "\n",
        "# 학습을 위한 tf.nn.dynamic_rnn을 선언합니다.\n",
        "# outputs : [batch_size, seq_length, hidden_size]\n",
        "outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, dtype=tf.float32)\n",
        "# ouputs을 [batch_size * seq_length, hidden_size]] 형태로 바꿉니다.\n",
        "output = tf.reshape(outputs, [-1, hidden_size])\n",
        "\n",
        "# 최종 출력값을 설정합니다.\n",
        "# logits : [batch_size * seq_length, vocab_size]\n",
        "logits = tf.matmul(output, softmax_w) + softmax_b\n",
        "probs = tf.nn.softmax(logits)\n",
        "\n",
        "# Cross Entropy 손실 함수를 정의합니다. \n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=target_data))\n",
        "\n",
        "# 옵티마이저를 선언하고 옵티마이저에 Gradient Clipping을 적용합니다.\n",
        "# grad_clip(=5)보다 큰 Gradient를 5로 Clippin합니다.\n",
        "tvars = tf.trainable_variables()\n",
        "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "train_step = optimizer.apply_gradients(zip(grads, tvars))\n",
        "\n",
        "# 세션을 열고 학습을 진행합니다.\n",
        "with tf.Session() as sess:\n",
        "    # 변수들에 초기값을 할당합니다.\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for e in range(num_epochs):\n",
        "        data_loader.reset_batch_pointer()\n",
        "        # 초기 상태값을 지정합니다.\n",
        "        state = sess.run(initial_state, feed_dict={state_batch_size : batch_size})\n",
        "\n",
        "        for b in range(data_loader.num_batches):\n",
        "            # x, y 데이터를 불러옵니다.\n",
        "            x, y = data_loader.next_batch()\n",
        "            # y에 one_hot 인코딩을 적용합니다. \n",
        "            y = tf.one_hot(y, vocab_size)            # y : [batch_size, seq_length, vocab_size]\n",
        "            y = tf.reshape(y, [-1, vocab_size])       # y : [batch_size * seq_length, vocab_size]\n",
        "            y = y.eval()\n",
        "\n",
        "            # feed-dict에 사용할 값들과 LSTM 초기 cell state(feed_dict[c])값과 hidden layer 출력값(feed_dict[h])을 지정합니다.\n",
        "            feed_dict = {input_data : x, target_data: y, state_batch_size : batch_size}\n",
        "            for i, (c, h) in enumerate(initial_state):\n",
        "                feed_dict[c] = state[i].c\n",
        "                feed_dict[h] = state[i].h\n",
        "\n",
        "            # 한스텝 학습을 진행합니다.\n",
        "            _, loss_print, state = sess.run([train_step, loss, final_state], feed_dict=feed_dict)\n",
        "\n",
        "            print(\"{}(학습한 배치개수)/{}(학습할 배치개수), 반복(epoch): {}, 손실함수(loss): {:.3f}\".format(\n",
        "                          e * data_loader.num_batches + b,\n",
        "                          num_epochs * data_loader.num_batches,\n",
        "                          (e+1), \n",
        "                          loss_print))\n",
        "\n",
        "    print(\"트레이닝이 끝났습니다!\")   \n",
        "    \n",
        "\n",
        "    # 샘플링 시작\n",
        "    print(\"샘플링을 시작합니다!\")\n",
        "    num_sampling = 4000  # 생성할 글자(Character)의 개수를 지정합니다. \n",
        "    prime = u' '         # 시작 글자를 ' '(공백)으로 지정합니다.\n",
        "    sampling_type = 1    # 샘플링 타입을 설정합니다.\n",
        "    state = sess.run(cell.zero_state(1, tf.float32)) # RNN의 최초 state값을 0으로 초기화합니다.\n",
        "\n",
        "    # Random Sampling을 위한 weighted_pick 함수를 정의합니다.\n",
        "    def weighted_pick(weights):\n",
        "        t = np.cumsum(weights)\n",
        "        s = np.sum(weights)\n",
        "        return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
        "\n",
        "    ret = prime       # 샘플링 결과를 리턴받을 ret 변수에 첫번째 글자를 할당합니다.\n",
        "    char = prime[-1]   # Char-RNN의 첫번쨰 인풋을 지정합니다.  \n",
        "    for n in range(num_sampling):\n",
        "        x = np.zeros((1, 1))\n",
        "        x[0, 0] = vocab[char]\n",
        "\n",
        "        # RNN을 한스텝 실행하고 Softmax 행렬을 리턴으로 받습니다.\n",
        "        feed_dict = {input_data: x, state_batch_size : 1, initial_state: state}\n",
        "        [probs_result, state] = sess.run([probs, final_state], feed_dict=feed_dict)         \n",
        "\n",
        "        # 불필요한 차원을 제거합니다.\n",
        "        # probs_result : (1,65) -> p : (65)\n",
        "        p = np.squeeze(probs_result)\n",
        "\n",
        "        # 샘플링 타입에 따라 3가지 종류로 샘플링 합니다.\n",
        "        # sampling_type : 0 -> 다음 글자를 예측할때 항상 argmax를 사용\n",
        "        # sampling_type : 1(defualt) -> 다음 글자를 예측할때 항상 random sampling을 사용\n",
        "        # sampling_type : 2 -> 다음 글자를 예측할때 이전 글자가 ' '(공백)이면 random sampling, 그렇지 않을 경우 argmax를 사용\n",
        "        if sampling_type == 0:\n",
        "            sample = np.argmax(p)\n",
        "        elif sampling_type == 2:\n",
        "            if char == ' ':\n",
        "                sample = weighted_pick(p)\n",
        "            else:\n",
        "                sample = np.argmax(p)\n",
        "        else:\n",
        "            sample = weighted_pick(p)\n",
        "\n",
        "        pred = chars[sample]\n",
        "        ret += pred     # 샘플링 결과에 현재 스텝에서 예측한 글자를 추가합니다. (예를들어 pred=L일 경우, ret = HEL -> HELL)\n",
        "        char = pred     # 예측한 글자를 다음 RNN의 인풋으로 사용합니다.\n",
        "\n",
        "    print(\"샘플링 결과:\")\n",
        "    print(ret)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Is-niNQC297",
        "outputId": "da0de2ba-5fe8-4e84-8b9c-0a324c7e7d66"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading preprocessed files\n",
            "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa3be13e810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa3be13e810>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa3be13e810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa3be13e810>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa3be15b2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa3be15b2d0>>: AttributeError: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa3be15b2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa3be15b2d0>>: AttributeError: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa3be1140d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa3be1140d0>>: AttributeError: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa3be1140d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa3be1140d0>>: AttributeError: module 'gast' has no attribute 'Str'\n",
            "0(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 7.166\n",
            "1(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 6.227\n",
            "2(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 1, 손실함수(loss): 5.883\n",
            "3(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 5.719\n",
            "4(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 5.502\n",
            "5(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 2, 손실함수(loss): 5.332\n",
            "6(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 3, 손실함수(loss): 5.322\n",
            "7(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 3, 손실함수(loss): 5.153\n",
            "8(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 3, 손실함수(loss): 5.013\n",
            "9(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 4, 손실함수(loss): 5.059\n",
            "10(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 4, 손실함수(loss): 4.912\n",
            "11(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 4, 손실함수(loss): 4.784\n",
            "12(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 5, 손실함수(loss): 4.857\n",
            "13(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 5, 손실함수(loss): 4.716\n",
            "14(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 5, 손실함수(loss): 4.569\n",
            "15(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 6, 손실함수(loss): 4.663\n",
            "16(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 6, 손실함수(loss): 4.532\n",
            "17(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 6, 손실함수(loss): 4.381\n",
            "18(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 7, 손실함수(loss): 4.472\n",
            "19(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 7, 손실함수(loss): 4.372\n",
            "20(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 7, 손실함수(loss): 4.220\n",
            "21(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 8, 손실함수(loss): 4.303\n",
            "22(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 8, 손실함수(loss): 4.221\n",
            "23(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 8, 손실함수(loss): 4.074\n",
            "24(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 9, 손실함수(loss): 4.155\n",
            "25(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 9, 손실함수(loss): 4.076\n",
            "26(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 9, 손실함수(loss): 3.932\n",
            "27(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 10, 손실함수(loss): 4.010\n",
            "28(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 10, 손실함수(loss): 3.931\n",
            "29(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 10, 손실함수(loss): 3.794\n",
            "30(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 11, 손실함수(loss): 3.871\n",
            "31(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 11, 손실함수(loss): 3.793\n",
            "32(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 11, 손실함수(loss): 3.657\n",
            "33(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 12, 손실함수(loss): 3.735\n",
            "34(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 12, 손실함수(loss): 3.654\n",
            "35(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 12, 손실함수(loss): 3.534\n",
            "36(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 13, 손실함수(loss): 3.605\n",
            "37(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 13, 손실함수(loss): 3.528\n",
            "38(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 13, 손실함수(loss): 3.411\n",
            "39(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 14, 손실함수(loss): 3.476\n",
            "40(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 14, 손실함수(loss): 3.402\n",
            "41(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 14, 손실함수(loss): 3.285\n",
            "42(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 15, 손실함수(loss): 3.352\n",
            "43(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 15, 손실함수(loss): 3.278\n",
            "44(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 15, 손실함수(loss): 3.168\n",
            "45(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 16, 손실함수(loss): 3.224\n",
            "46(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 16, 손실함수(loss): 3.155\n",
            "47(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 16, 손실함수(loss): 3.050\n",
            "48(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 17, 손실함수(loss): 3.100\n",
            "49(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 17, 손실함수(loss): 3.027\n",
            "50(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 17, 손실함수(loss): 2.932\n",
            "51(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 18, 손실함수(loss): 2.983\n",
            "52(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 18, 손실함수(loss): 2.888\n",
            "53(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 18, 손실함수(loss): 2.817\n",
            "54(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 19, 손실함수(loss): 2.867\n",
            "55(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 19, 손실함수(loss): 2.769\n",
            "56(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 19, 손실함수(loss): 2.700\n",
            "57(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 20, 손실함수(loss): 2.761\n",
            "58(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 20, 손실함수(loss): 2.655\n",
            "59(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 20, 손실함수(loss): 2.593\n",
            "60(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 21, 손실함수(loss): 2.652\n",
            "61(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 21, 손실함수(loss): 2.531\n",
            "62(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 21, 손실함수(loss): 2.558\n",
            "63(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 22, 손실함수(loss): 2.525\n",
            "64(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 22, 손실함수(loss): 2.457\n",
            "65(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 22, 손실함수(loss): 2.387\n",
            "66(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 23, 손실함수(loss): 2.437\n",
            "67(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 23, 손실함수(loss): 2.298\n",
            "68(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 23, 손실함수(loss): 2.317\n",
            "69(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 24, 손실함수(loss): 2.300\n",
            "70(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 24, 손실함수(loss): 2.195\n",
            "71(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 24, 손실함수(loss): 2.170\n",
            "72(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 25, 손실함수(loss): 2.223\n",
            "73(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 25, 손실함수(loss): 2.074\n",
            "74(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 25, 손실함수(loss): 2.090\n",
            "75(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 26, 손실함수(loss): 2.080\n",
            "76(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 26, 손실함수(loss): 1.973\n",
            "77(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 26, 손실함수(loss): 1.928\n",
            "78(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 27, 손실함수(loss): 1.973\n",
            "79(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 27, 손실함수(loss): 1.851\n",
            "80(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 27, 손실함수(loss): 1.832\n",
            "81(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 28, 손실함수(loss): 1.851\n",
            "82(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 28, 손실함수(loss): 1.756\n",
            "83(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 28, 손실함수(loss): 1.735\n",
            "84(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 29, 손실함수(loss): 1.740\n",
            "85(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 29, 손실함수(loss): 1.644\n",
            "86(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 29, 손실함수(loss): 1.621\n",
            "87(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 30, 손실함수(loss): 1.713\n",
            "88(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 30, 손실함수(loss): 1.529\n",
            "89(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 30, 손실함수(loss): 1.636\n",
            "90(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 31, 손실함수(loss): 1.561\n",
            "91(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 31, 손실함수(loss): 1.584\n",
            "92(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 31, 손실함수(loss): 1.510\n",
            "93(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 32, 손실함수(loss): 1.618\n",
            "94(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 32, 손실함수(loss): 1.413\n",
            "95(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 32, 손실함수(loss): 1.478\n",
            "96(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 33, 손실함수(loss): 1.398\n",
            "97(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 33, 손실함수(loss): 1.359\n",
            "98(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 33, 손실함수(loss): 1.310\n",
            "99(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 34, 손실함수(loss): 1.385\n",
            "100(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 34, 손실함수(loss): 1.223\n",
            "101(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 34, 손실함수(loss): 1.284\n",
            "102(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 35, 손실함수(loss): 1.253\n",
            "103(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 35, 손실함수(loss): 1.196\n",
            "104(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 35, 손실함수(loss): 1.149\n",
            "105(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 36, 손실함수(loss): 1.177\n",
            "106(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 36, 손실함수(loss): 1.089\n",
            "107(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 36, 손실함수(loss): 1.030\n",
            "108(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 37, 손실함수(loss): 1.123\n",
            "109(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 37, 손실함수(loss): 1.009\n",
            "110(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 37, 손실함수(loss): 0.964\n",
            "111(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 38, 손실함수(loss): 1.037\n",
            "112(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 38, 손실함수(loss): 0.899\n",
            "113(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 38, 손실함수(loss): 0.886\n",
            "114(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 39, 손실함수(loss): 0.952\n",
            "115(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 39, 손실함수(loss): 0.842\n",
            "116(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 39, 손실함수(loss): 0.844\n",
            "117(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 40, 손실함수(loss): 0.853\n",
            "118(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 40, 손실함수(loss): 0.756\n",
            "119(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 40, 손실함수(loss): 0.753\n",
            "120(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 41, 손실함수(loss): 0.781\n",
            "121(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 41, 손실함수(loss): 0.696\n",
            "122(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 41, 손실함수(loss): 0.653\n",
            "123(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 42, 손실함수(loss): 0.716\n",
            "124(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 42, 손실함수(loss): 0.611\n",
            "125(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 42, 손실함수(loss): 0.589\n",
            "126(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 43, 손실함수(loss): 0.662\n",
            "127(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 43, 손실함수(loss): 0.535\n",
            "128(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 43, 손실함수(loss): 0.518\n",
            "129(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 44, 손실함수(loss): 0.606\n",
            "130(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 44, 손실함수(loss): 0.470\n",
            "131(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 44, 손실함수(loss): 0.451\n",
            "132(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 45, 손실함수(loss): 0.541\n",
            "133(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 45, 손실함수(loss): 0.420\n",
            "134(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 45, 손실함수(loss): 0.389\n",
            "135(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 46, 손실함수(loss): 0.493\n",
            "136(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 46, 손실함수(loss): 0.377\n",
            "137(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 46, 손실함수(loss): 0.341\n",
            "138(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 47, 손실함수(loss): 0.444\n",
            "139(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 47, 손실함수(loss): 0.329\n",
            "140(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 47, 손실함수(loss): 0.309\n",
            "141(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 48, 손실함수(loss): 0.413\n",
            "142(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 48, 손실함수(loss): 0.287\n",
            "143(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 48, 손실함수(loss): 0.268\n",
            "144(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 49, 손실함수(loss): 0.376\n",
            "145(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 49, 손실함수(loss): 0.254\n",
            "146(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 49, 손실함수(loss): 0.237\n",
            "147(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 50, 손실함수(loss): 0.348\n",
            "148(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 50, 손실함수(loss): 0.224\n",
            "149(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 50, 손실함수(loss): 0.206\n",
            "150(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 51, 손실함수(loss): 0.323\n",
            "151(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 51, 손실함수(loss): 0.200\n",
            "152(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 51, 손실함수(loss): 0.183\n",
            "153(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 52, 손실함수(loss): 0.300\n",
            "154(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 52, 손실함수(loss): 0.180\n",
            "155(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 52, 손실함수(loss): 0.163\n",
            "156(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 53, 손실함수(loss): 0.280\n",
            "157(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 53, 손실함수(loss): 0.164\n",
            "158(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 53, 손실함수(loss): 0.145\n",
            "159(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 54, 손실함수(loss): 0.266\n",
            "160(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 54, 손실함수(loss): 0.145\n",
            "161(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 54, 손실함수(loss): 0.133\n",
            "162(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 55, 손실함수(loss): 0.248\n",
            "163(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 55, 손실함수(loss): 0.131\n",
            "164(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 55, 손실함수(loss): 0.119\n",
            "165(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 56, 손실함수(loss): 0.234\n",
            "166(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 56, 손실함수(loss): 0.118\n",
            "167(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 56, 손실함수(loss): 0.107\n",
            "168(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 57, 손실함수(loss): 0.222\n",
            "169(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 57, 손실함수(loss): 0.107\n",
            "170(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 57, 손실함수(loss): 0.097\n",
            "171(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 58, 손실함수(loss): 0.212\n",
            "172(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 58, 손실함수(loss): 0.098\n",
            "173(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 58, 손실함수(loss): 0.089\n",
            "174(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 59, 손실함수(loss): 0.202\n",
            "175(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 59, 손실함수(loss): 0.089\n",
            "176(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 59, 손실함수(loss): 0.081\n",
            "177(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 60, 손실함수(loss): 0.193\n",
            "178(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 60, 손실함수(loss): 0.082\n",
            "179(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 60, 손실함수(loss): 0.074\n",
            "180(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 61, 손실함수(loss): 0.185\n",
            "181(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 61, 손실함수(loss): 0.076\n",
            "182(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 61, 손실함수(loss): 0.069\n",
            "183(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 62, 손실함수(loss): 0.177\n",
            "184(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 62, 손실함수(loss): 0.070\n",
            "185(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 62, 손실함수(loss): 0.064\n",
            "186(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 63, 손실함수(loss): 0.170\n",
            "187(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 63, 손실함수(loss): 0.065\n",
            "188(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 63, 손실함수(loss): 0.059\n",
            "189(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 64, 손실함수(loss): 0.164\n",
            "190(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 64, 손실함수(loss): 0.061\n",
            "191(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 64, 손실함수(loss): 0.056\n",
            "192(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 65, 손실함수(loss): 0.158\n",
            "193(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 65, 손실함수(loss): 0.056\n",
            "194(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 65, 손실함수(loss): 0.051\n",
            "195(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 66, 손실함수(loss): 0.153\n",
            "196(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 66, 손실함수(loss): 0.053\n",
            "197(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 66, 손실함수(loss): 0.048\n",
            "198(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 67, 손실함수(loss): 0.148\n",
            "199(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 67, 손실함수(loss): 0.050\n",
            "200(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 67, 손실함수(loss): 0.045\n",
            "201(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 68, 손실함수(loss): 0.143\n",
            "202(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 68, 손실함수(loss): 0.047\n",
            "203(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 68, 손실함수(loss): 0.043\n",
            "204(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 69, 손실함수(loss): 0.138\n",
            "205(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 69, 손실함수(loss): 0.044\n",
            "206(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 69, 손실함수(loss): 0.040\n",
            "207(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 70, 손실함수(loss): 0.134\n",
            "208(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 70, 손실함수(loss): 0.042\n",
            "209(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 70, 손실함수(loss): 0.038\n",
            "210(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 71, 손실함수(loss): 0.130\n",
            "211(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 71, 손실함수(loss): 0.039\n",
            "212(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 71, 손실함수(loss): 0.036\n",
            "213(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 72, 손실함수(loss): 0.126\n",
            "214(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 72, 손실함수(loss): 0.037\n",
            "215(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 72, 손실함수(loss): 0.035\n",
            "216(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 73, 손실함수(loss): 0.122\n",
            "217(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 73, 손실함수(loss): 0.035\n",
            "218(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 73, 손실함수(loss): 0.033\n",
            "219(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 74, 손실함수(loss): 0.119\n",
            "220(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 74, 손실함수(loss): 0.034\n",
            "221(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 74, 손실함수(loss): 0.032\n",
            "222(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 75, 손실함수(loss): 0.116\n",
            "223(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 75, 손실함수(loss): 0.032\n",
            "224(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 75, 손실함수(loss): 0.030\n",
            "225(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 76, 손실함수(loss): 0.113\n",
            "226(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 76, 손실함수(loss): 0.030\n",
            "227(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 76, 손실함수(loss): 0.029\n",
            "228(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 77, 손실함수(loss): 0.110\n",
            "229(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 77, 손실함수(loss): 0.029\n",
            "230(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 77, 손실함수(loss): 0.028\n",
            "231(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 78, 손실함수(loss): 0.107\n",
            "232(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 78, 손실함수(loss): 0.028\n",
            "233(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 78, 손실함수(loss): 0.027\n",
            "234(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 79, 손실함수(loss): 0.104\n",
            "235(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 79, 손실함수(loss): 0.027\n",
            "236(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 79, 손실함수(loss): 0.026\n",
            "237(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 80, 손실함수(loss): 0.102\n",
            "238(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 80, 손실함수(loss): 0.026\n",
            "239(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 80, 손실함수(loss): 0.025\n",
            "240(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 81, 손실함수(loss): 0.099\n",
            "241(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 81, 손실함수(loss): 0.025\n",
            "242(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 81, 손실함수(loss): 0.024\n",
            "243(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 82, 손실함수(loss): 0.097\n",
            "244(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 82, 손실함수(loss): 0.024\n",
            "245(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 82, 손실함수(loss): 0.023\n",
            "246(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 83, 손실함수(loss): 0.095\n",
            "247(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 83, 손실함수(loss): 0.023\n",
            "248(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 83, 손실함수(loss): 0.023\n",
            "249(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 84, 손실함수(loss): 0.093\n",
            "250(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 84, 손실함수(loss): 0.022\n",
            "251(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 84, 손실함수(loss): 0.022\n",
            "252(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 85, 손실함수(loss): 0.091\n",
            "253(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 85, 손실함수(loss): 0.022\n",
            "254(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 85, 손실함수(loss): 0.021\n",
            "255(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 86, 손실함수(loss): 0.089\n",
            "256(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 86, 손실함수(loss): 0.021\n",
            "257(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 86, 손실함수(loss): 0.020\n",
            "258(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 87, 손실함수(loss): 0.087\n",
            "259(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 87, 손실함수(loss): 0.020\n",
            "260(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 87, 손실함수(loss): 0.020\n",
            "261(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 88, 손실함수(loss): 0.085\n",
            "262(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 88, 손실함수(loss): 0.020\n",
            "263(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 88, 손실함수(loss): 0.019\n",
            "264(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 89, 손실함수(loss): 0.083\n",
            "265(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 89, 손실함수(loss): 0.019\n",
            "266(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 89, 손실함수(loss): 0.019\n",
            "267(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 90, 손실함수(loss): 0.082\n",
            "268(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 90, 손실함수(loss): 0.019\n",
            "269(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 90, 손실함수(loss): 0.018\n",
            "270(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 91, 손실함수(loss): 0.080\n",
            "271(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 91, 손실함수(loss): 0.018\n",
            "272(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 91, 손실함수(loss): 0.018\n",
            "273(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 92, 손실함수(loss): 0.079\n",
            "274(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 92, 손실함수(loss): 0.018\n",
            "275(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 92, 손실함수(loss): 0.017\n",
            "276(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 93, 손실함수(loss): 0.077\n",
            "277(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 93, 손실함수(loss): 0.017\n",
            "278(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 93, 손실함수(loss): 0.017\n",
            "279(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 94, 손실함수(loss): 0.076\n",
            "280(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 94, 손실함수(loss): 0.017\n",
            "281(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 94, 손실함수(loss): 0.016\n",
            "282(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 95, 손실함수(loss): 0.074\n",
            "283(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 95, 손실함수(loss): 0.016\n",
            "284(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 95, 손실함수(loss): 0.016\n",
            "285(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 96, 손실함수(loss): 0.073\n",
            "286(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 96, 손실함수(loss): 0.016\n",
            "287(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 96, 손실함수(loss): 0.016\n",
            "288(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 97, 손실함수(loss): 0.072\n",
            "289(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 97, 손실함수(loss): 0.016\n",
            "290(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 97, 손실함수(loss): 0.015\n",
            "291(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 98, 손실함수(loss): 0.070\n",
            "292(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 98, 손실함수(loss): 0.015\n",
            "293(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 98, 손실함수(loss): 0.015\n",
            "294(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 99, 손실함수(loss): 0.069\n",
            "295(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 99, 손실함수(loss): 0.015\n",
            "296(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 99, 손실함수(loss): 0.015\n",
            "297(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 100, 손실함수(loss): 0.068\n",
            "298(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 100, 손실함수(loss): 0.015\n",
            "299(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 100, 손실함수(loss): 0.014\n",
            "300(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 101, 손실함수(loss): 0.067\n",
            "301(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 101, 손실함수(loss): 0.014\n",
            "302(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 101, 손실함수(loss): 0.014\n",
            "303(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 102, 손실함수(loss): 0.066\n",
            "304(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 102, 손실함수(loss): 0.014\n",
            "305(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 102, 손실함수(loss): 0.014\n",
            "306(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 103, 손실함수(loss): 0.064\n",
            "307(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 103, 손실함수(loss): 0.014\n",
            "308(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 103, 손실함수(loss): 0.013\n",
            "309(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 104, 손실함수(loss): 0.063\n",
            "310(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 104, 손실함수(loss): 0.013\n",
            "311(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 104, 손실함수(loss): 0.013\n",
            "312(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 105, 손실함수(loss): 0.062\n",
            "313(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 105, 손실함수(loss): 0.013\n",
            "314(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 105, 손실함수(loss): 0.013\n",
            "315(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 106, 손실함수(loss): 0.061\n",
            "316(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 106, 손실함수(loss): 0.013\n",
            "317(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 106, 손실함수(loss): 0.012\n",
            "318(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 107, 손실함수(loss): 0.060\n",
            "319(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 107, 손실함수(loss): 0.013\n",
            "320(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 107, 손실함수(loss): 0.012\n",
            "321(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 108, 손실함수(loss): 0.060\n",
            "322(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 108, 손실함수(loss): 0.012\n",
            "323(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 108, 손실함수(loss): 0.012\n",
            "324(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 109, 손실함수(loss): 0.059\n",
            "325(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 109, 손실함수(loss): 0.012\n",
            "326(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 109, 손실함수(loss): 0.012\n",
            "327(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 110, 손실함수(loss): 0.058\n",
            "328(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 110, 손실함수(loss): 0.012\n",
            "329(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 110, 손실함수(loss): 0.011\n",
            "330(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 111, 손실함수(loss): 0.057\n",
            "331(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 111, 손실함수(loss): 0.012\n",
            "332(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 111, 손실함수(loss): 0.011\n",
            "333(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 112, 손실함수(loss): 0.056\n",
            "334(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 112, 손실함수(loss): 0.011\n",
            "335(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 112, 손실함수(loss): 0.011\n",
            "336(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 113, 손실함수(loss): 0.055\n",
            "337(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 113, 손실함수(loss): 0.011\n",
            "338(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 113, 손실함수(loss): 0.011\n",
            "339(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 114, 손실함수(loss): 0.055\n",
            "340(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 114, 손실함수(loss): 0.011\n",
            "341(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 114, 손실함수(loss): 0.011\n",
            "342(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 115, 손실함수(loss): 0.054\n",
            "343(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 115, 손실함수(loss): 0.011\n",
            "344(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 115, 손실함수(loss): 0.010\n",
            "345(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 116, 손실함수(loss): 0.053\n",
            "346(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 116, 손실함수(loss): 0.011\n",
            "347(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 116, 손실함수(loss): 0.010\n",
            "348(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 117, 손실함수(loss): 0.052\n",
            "349(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 117, 손실함수(loss): 0.010\n",
            "350(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 117, 손실함수(loss): 0.010\n",
            "351(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 118, 손실함수(loss): 0.052\n",
            "352(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 118, 손실함수(loss): 0.010\n",
            "353(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 118, 손실함수(loss): 0.010\n",
            "354(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 119, 손실함수(loss): 0.051\n",
            "355(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 119, 손실함수(loss): 0.010\n",
            "356(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 119, 손실함수(loss): 0.010\n",
            "357(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 120, 손실함수(loss): 0.050\n",
            "358(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 120, 손실함수(loss): 0.010\n",
            "359(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 120, 손실함수(loss): 0.010\n",
            "360(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 121, 손실함수(loss): 0.050\n",
            "361(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 121, 손실함수(loss): 0.010\n",
            "362(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 121, 손실함수(loss): 0.009\n",
            "363(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 122, 손실함수(loss): 0.049\n",
            "364(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 122, 손실함수(loss): 0.009\n",
            "365(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 122, 손실함수(loss): 0.009\n",
            "366(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 123, 손실함수(loss): 0.049\n",
            "367(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 123, 손실함수(loss): 0.009\n",
            "368(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 123, 손실함수(loss): 0.009\n",
            "369(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 124, 손실함수(loss): 0.048\n",
            "370(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 124, 손실함수(loss): 0.009\n",
            "371(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 124, 손실함수(loss): 0.009\n",
            "372(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 125, 손실함수(loss): 0.047\n",
            "373(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 125, 손실함수(loss): 0.009\n",
            "374(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 125, 손실함수(loss): 0.009\n",
            "375(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 126, 손실함수(loss): 0.047\n",
            "376(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 126, 손실함수(loss): 0.009\n",
            "377(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 126, 손실함수(loss): 0.009\n",
            "378(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 127, 손실함수(loss): 0.046\n",
            "379(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 127, 손실함수(loss): 0.009\n",
            "380(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 127, 손실함수(loss): 0.008\n",
            "381(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 128, 손실함수(loss): 0.046\n",
            "382(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 128, 손실함수(loss): 0.009\n",
            "383(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 128, 손실함수(loss): 0.008\n",
            "384(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 129, 손실함수(loss): 0.045\n",
            "385(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 129, 손실함수(loss): 0.008\n",
            "386(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 129, 손실함수(loss): 0.008\n",
            "387(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 130, 손실함수(loss): 0.045\n",
            "388(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 130, 손실함수(loss): 0.008\n",
            "389(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 130, 손실함수(loss): 0.008\n",
            "390(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 131, 손실함수(loss): 0.044\n",
            "391(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 131, 손실함수(loss): 0.008\n",
            "392(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 131, 손실함수(loss): 0.008\n",
            "393(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 132, 손실함수(loss): 0.044\n",
            "394(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 132, 손실함수(loss): 0.008\n",
            "395(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 132, 손실함수(loss): 0.008\n",
            "396(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 133, 손실함수(loss): 0.043\n",
            "397(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 133, 손실함수(loss): 0.008\n",
            "398(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 133, 손실함수(loss): 0.008\n",
            "399(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 134, 손실함수(loss): 0.043\n",
            "400(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 134, 손실함수(loss): 0.008\n",
            "401(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 134, 손실함수(loss): 0.008\n",
            "402(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 135, 손실함수(loss): 0.043\n",
            "403(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 135, 손실함수(loss): 0.008\n",
            "404(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 135, 손실함수(loss): 0.008\n",
            "405(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 136, 손실함수(loss): 0.042\n",
            "406(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 136, 손실함수(loss): 0.008\n",
            "407(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 136, 손실함수(loss): 0.007\n",
            "408(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 137, 손실함수(loss): 0.042\n",
            "409(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 137, 손실함수(loss): 0.007\n",
            "410(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 137, 손실함수(loss): 0.007\n",
            "411(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 138, 손실함수(loss): 0.041\n",
            "412(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 138, 손실함수(loss): 0.007\n",
            "413(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 138, 손실함수(loss): 0.007\n",
            "414(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 139, 손실함수(loss): 0.041\n",
            "415(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 139, 손실함수(loss): 0.007\n",
            "416(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 139, 손실함수(loss): 0.007\n",
            "417(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 140, 손실함수(loss): 0.041\n",
            "418(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 140, 손실함수(loss): 0.007\n",
            "419(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 140, 손실함수(loss): 0.007\n",
            "420(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 141, 손실함수(loss): 0.040\n",
            "421(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 141, 손실함수(loss): 0.007\n",
            "422(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 141, 손실함수(loss): 0.007\n",
            "423(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 142, 손실함수(loss): 0.040\n",
            "424(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 142, 손실함수(loss): 0.007\n",
            "425(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 142, 손실함수(loss): 0.007\n",
            "426(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 143, 손실함수(loss): 0.040\n",
            "427(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 143, 손실함수(loss): 0.007\n",
            "428(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 143, 손실함수(loss): 0.007\n",
            "429(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 144, 손실함수(loss): 0.039\n",
            "430(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 144, 손실함수(loss): 0.007\n",
            "431(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 144, 손실함수(loss): 0.007\n",
            "432(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 145, 손실함수(loss): 0.039\n",
            "433(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 145, 손실함수(loss): 0.007\n",
            "434(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 145, 손실함수(loss): 0.007\n",
            "435(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 146, 손실함수(loss): 0.039\n",
            "436(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 146, 손실함수(loss): 0.007\n",
            "437(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 146, 손실함수(loss): 0.006\n",
            "438(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 147, 손실함수(loss): 0.038\n",
            "439(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 147, 손실함수(loss): 0.007\n",
            "440(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 147, 손실함수(loss): 0.006\n",
            "441(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 148, 손실함수(loss): 0.038\n",
            "442(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 148, 손실함수(loss): 0.006\n",
            "443(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 148, 손실함수(loss): 0.006\n",
            "444(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 149, 손실함수(loss): 0.038\n",
            "445(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 149, 손실함수(loss): 0.006\n",
            "446(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 149, 손실함수(loss): 0.006\n",
            "447(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 150, 손실함수(loss): 0.037\n",
            "448(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 150, 손실함수(loss): 0.006\n",
            "449(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 150, 손실함수(loss): 0.006\n",
            "450(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 151, 손실함수(loss): 0.037\n",
            "451(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 151, 손실함수(loss): 0.006\n",
            "452(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 151, 손실함수(loss): 0.006\n",
            "453(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 152, 손실함수(loss): 0.037\n",
            "454(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 152, 손실함수(loss): 0.006\n",
            "455(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 152, 손실함수(loss): 0.006\n",
            "456(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 153, 손실함수(loss): 0.036\n",
            "457(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 153, 손실함수(loss): 0.006\n",
            "458(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 153, 손실함수(loss): 0.006\n",
            "459(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 154, 손실함수(loss): 0.036\n",
            "460(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 154, 손실함수(loss): 0.006\n",
            "461(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 154, 손실함수(loss): 0.006\n",
            "462(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 155, 손실함수(loss): 0.036\n",
            "463(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 155, 손실함수(loss): 0.006\n",
            "464(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 155, 손실함수(loss): 0.006\n",
            "465(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 156, 손실함수(loss): 0.036\n",
            "466(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 156, 손실함수(loss): 0.006\n",
            "467(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 156, 손실함수(loss): 0.006\n",
            "468(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 157, 손실함수(loss): 0.035\n",
            "469(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 157, 손실함수(loss): 0.006\n",
            "470(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 157, 손실함수(loss): 0.006\n",
            "471(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 158, 손실함수(loss): 0.035\n",
            "472(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 158, 손실함수(loss): 0.006\n",
            "473(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 158, 손실함수(loss): 0.006\n",
            "474(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 159, 손실함수(loss): 0.035\n",
            "475(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 159, 손실함수(loss): 0.006\n",
            "476(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 159, 손실함수(loss): 0.005\n",
            "477(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 160, 손실함수(loss): 0.035\n",
            "478(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 160, 손실함수(loss): 0.006\n",
            "479(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 160, 손실함수(loss): 0.005\n",
            "480(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 161, 손실함수(loss): 0.034\n",
            "481(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 161, 손실함수(loss): 0.005\n",
            "482(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 161, 손실함수(loss): 0.005\n",
            "483(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 162, 손실함수(loss): 0.034\n",
            "484(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 162, 손실함수(loss): 0.005\n",
            "485(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 162, 손실함수(loss): 0.005\n",
            "486(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 163, 손실함수(loss): 0.034\n",
            "487(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 163, 손실함수(loss): 0.005\n",
            "488(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 163, 손실함수(loss): 0.005\n",
            "489(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 164, 손실함수(loss): 0.034\n",
            "490(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 164, 손실함수(loss): 0.005\n",
            "491(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 164, 손실함수(loss): 0.005\n",
            "492(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 165, 손실함수(loss): 0.034\n",
            "493(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 165, 손실함수(loss): 0.005\n",
            "494(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 165, 손실함수(loss): 0.005\n",
            "495(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 166, 손실함수(loss): 0.033\n",
            "496(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 166, 손실함수(loss): 0.005\n",
            "497(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 166, 손실함수(loss): 0.005\n",
            "498(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 167, 손실함수(loss): 0.033\n",
            "499(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 167, 손실함수(loss): 0.005\n",
            "500(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 167, 손실함수(loss): 0.005\n",
            "501(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 168, 손실함수(loss): 0.033\n",
            "502(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 168, 손실함수(loss): 0.005\n",
            "503(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 168, 손실함수(loss): 0.005\n",
            "504(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 169, 손실함수(loss): 0.033\n",
            "505(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 169, 손실함수(loss): 0.005\n",
            "506(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 169, 손실함수(loss): 0.005\n",
            "507(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 170, 손실함수(loss): 0.033\n",
            "508(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 170, 손실함수(loss): 0.005\n",
            "509(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 170, 손실함수(loss): 0.005\n",
            "510(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 171, 손실함수(loss): 0.032\n",
            "511(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 171, 손실함수(loss): 0.005\n",
            "512(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 171, 손실함수(loss): 0.005\n",
            "513(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 172, 손실함수(loss): 0.032\n",
            "514(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 172, 손실함수(loss): 0.005\n",
            "515(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 172, 손실함수(loss): 0.005\n",
            "516(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 173, 손실함수(loss): 0.032\n",
            "517(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 173, 손실함수(loss): 0.005\n",
            "518(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 173, 손실함수(loss): 0.005\n",
            "519(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 174, 손실함수(loss): 0.032\n",
            "520(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 174, 손실함수(loss): 0.005\n",
            "521(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 174, 손실함수(loss): 0.005\n",
            "522(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 175, 손실함수(loss): 0.032\n",
            "523(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 175, 손실함수(loss): 0.005\n",
            "524(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 175, 손실함수(loss): 0.005\n",
            "525(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 176, 손실함수(loss): 0.031\n",
            "526(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 176, 손실함수(loss): 0.005\n",
            "527(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 176, 손실함수(loss): 0.004\n",
            "528(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 177, 손실함수(loss): 0.031\n",
            "529(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 177, 손실함수(loss): 0.005\n",
            "530(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 177, 손실함수(loss): 0.004\n",
            "531(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 178, 손실함수(loss): 0.031\n",
            "532(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 178, 손실함수(loss): 0.005\n",
            "533(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 178, 손실함수(loss): 0.004\n",
            "534(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 179, 손실함수(loss): 0.031\n",
            "535(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 179, 손실함수(loss): 0.004\n",
            "536(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 179, 손실함수(loss): 0.004\n",
            "537(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 180, 손실함수(loss): 0.031\n",
            "538(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 180, 손실함수(loss): 0.004\n",
            "539(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 180, 손실함수(loss): 0.004\n",
            "540(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 181, 손실함수(loss): 0.031\n",
            "541(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 181, 손실함수(loss): 0.004\n",
            "542(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 181, 손실함수(loss): 0.004\n",
            "543(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 182, 손실함수(loss): 0.031\n",
            "544(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 182, 손실함수(loss): 0.004\n",
            "545(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 182, 손실함수(loss): 0.004\n",
            "546(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 183, 손실함수(loss): 0.030\n",
            "547(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 183, 손실함수(loss): 0.004\n",
            "548(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 183, 손실함수(loss): 0.004\n",
            "549(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 184, 손실함수(loss): 0.030\n",
            "550(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 184, 손실함수(loss): 0.004\n",
            "551(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 184, 손실함수(loss): 0.004\n",
            "552(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 185, 손실함수(loss): 0.030\n",
            "553(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 185, 손실함수(loss): 0.004\n",
            "554(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 185, 손실함수(loss): 0.004\n",
            "555(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 186, 손실함수(loss): 0.030\n",
            "556(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 186, 손실함수(loss): 0.004\n",
            "557(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 186, 손실함수(loss): 0.004\n",
            "558(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 187, 손실함수(loss): 0.030\n",
            "559(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 187, 손실함수(loss): 0.004\n",
            "560(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 187, 손실함수(loss): 0.004\n",
            "561(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 188, 손실함수(loss): 0.030\n",
            "562(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 188, 손실함수(loss): 0.004\n",
            "563(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 188, 손실함수(loss): 0.004\n",
            "564(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 189, 손실함수(loss): 0.030\n",
            "565(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 189, 손실함수(loss): 0.004\n",
            "566(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 189, 손실함수(loss): 0.004\n",
            "567(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 190, 손실함수(loss): 0.029\n",
            "568(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 190, 손실함수(loss): 0.004\n",
            "569(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 190, 손실함수(loss): 0.004\n",
            "570(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 191, 손실함수(loss): 0.029\n",
            "571(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 191, 손실함수(loss): 0.004\n",
            "572(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 191, 손실함수(loss): 0.004\n",
            "573(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 192, 손실함수(loss): 0.029\n",
            "574(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 192, 손실함수(loss): 0.004\n",
            "575(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 192, 손실함수(loss): 0.004\n",
            "576(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 193, 손실함수(loss): 0.029\n",
            "577(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 193, 손실함수(loss): 0.004\n",
            "578(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 193, 손실함수(loss): 0.004\n",
            "579(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 194, 손실함수(loss): 0.029\n",
            "580(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 194, 손실함수(loss): 0.004\n",
            "581(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 194, 손실함수(loss): 0.004\n",
            "582(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 195, 손실함수(loss): 0.029\n",
            "583(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 195, 손실함수(loss): 0.004\n",
            "584(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 195, 손실함수(loss): 0.004\n",
            "585(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 196, 손실함수(loss): 0.029\n",
            "586(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 196, 손실함수(loss): 0.004\n",
            "587(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 196, 손실함수(loss): 0.004\n",
            "588(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 197, 손실함수(loss): 0.029\n",
            "589(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 197, 손실함수(loss): 0.004\n",
            "590(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 197, 손실함수(loss): 0.004\n",
            "591(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 198, 손실함수(loss): 0.028\n",
            "592(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 198, 손실함수(loss): 0.004\n",
            "593(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 198, 손실함수(loss): 0.004\n",
            "594(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 199, 손실함수(loss): 0.028\n",
            "595(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 199, 손실함수(loss): 0.004\n",
            "596(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 199, 손실함수(loss): 0.004\n",
            "597(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 200, 손실함수(loss): 0.028\n",
            "598(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 200, 손실함수(loss): 0.004\n",
            "599(학습한 배치개수)/600(학습할 배치개수), 반복(epoch): 200, 손실함수(loss): 0.004\n",
            "트레이닝이 끝났습니다!\n",
            "샘플링을 시작합니다!\n",
            "샘플링 결과:\n",
            " 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다.\n",
            "그러나 소녀는\n",
            "“하나도 버리지 마라.”\n",
            "산마루께로 올라갔다.\n",
            "맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다.\n",
            "누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다. 유달리 주위가 조용해진 일날이 움놀놀 었는다. 어제내 가 용지 않는다. 생어는 소을 그리 날, 허대. 갈꽃을 안던 로 아한이 무우킨 그른 소년의 몸기에서 가운낸 멈해멈꽃, 이번맵둑지””\n",
            "“마리꽃.”\n",
            "께송이라 생달비를 가로 있었다. 요간며 찔찔가, 찔이 패패해 덩패붓붓를 교어지던 게 돌갔다.\n",
            "소을 와에 손녀도게 없장이렇는는 달줄년 주을 대던석섰서밭이…라….”\n",
            "“그럼, 누워 있어야지.”\n",
            "“하도 갑갑해서 나왔다. ……참, 그 날 재밌었어……. 그런데그 날 어디서 이런 물이 들었는지 잘 지지 않는다.”\n",
            "소녀가 분홍 스웨터 앞자락을 내려다본다. 거기에 검붉은 진흙물 같은 게 들어 있었다.\n",
            "소녀가 가만히 보보니, 산 그을 송아지고 는 워지 밖밖.서.\n",
            "이 제 잊돌아아버지?도 가허 덜물어 났다.\n",
            "소녀의 주곁이 허르아아왔다 범대, 자기 에손술러한가가슭냥밭해숫단단풍이 5음해름 된다 참렸다. \n",
            "시양기 했이다. 그런데도 소녀의 몸 그편으에 가아을 만 속에서 이업워지고 있다. “저”\n",
            "“모르여“후 맛벌 우어 오 느냐 날 랬이다.\n",
            "소녀가 가져을 돌아오는 길에 이는 물 장허라 하타아 우줄 옮기버다고빨, 소년오기 에부터 대자잠기가 재간이 포주는 르면 수 숫리 보다. 얼굴이 비릎 마빛로 꽃 안을 본다.\n",
            "“그, 이번에 이끌켰켰\n",
            "한건은 얼개가울로 나왔다.”\n",
            "소녀의 이마야아 있달, 소년은 몰냥 한 아버지는 한 어직 소년었다.\n",
            "저 새어 가지날 은 저 있었다.\n",
            "소녀가 가까행 와기꽃 이꽃이 실룩생각만갑란 했다. 남어 재맛간이 열열 생움친가 매 닭 찔던 호해해 춤다.”\n",
            "“이허 또 번 훑어지람 것었다. 는생왼 허이 들아 물다 위에 가 새기 빛시했다. 갈더더지 거딤기서 덜난으했다. 새을 모행 은기 있?”\n",
            "소녀가 것아 새는야 헛닌 같 뿐았편이 소년걸 걸음을 왔는다 같은 바따가밖에 말을 가투게 돌아아서 온 뵈지 않았다.\n",
            "다아 날 우은 기을 앉아 내왼 볼 볼의 바었는다.\n",
            "수조룩보, 데, 있잇어면 앉지간다. 보와 가만도 생비게 건다. 있다가 그빗, 소녀가 호타나는으해 원, 줬다.\n",
            "“모길에 이봐 는우니 조개여\n",
            "“야만.”\n",
            "“그루린 날다. 송이가 몇 개울가로 나왔다. 소녀의 오그지 등에서 무돈 될 얼굴도로 꽃닥.,\n",
            "보지나시떡 자더만 않도더다. 풍다보던 했이었다. 그저 건 대림자가 있는 걸 알는 걸 길을 모갔언.\n",
            "이서 소녀는 이마 멀기 달아다고 더쭐골 .”\n",
            "체 허마아 날일이다. 그러끊가 요맺, 소녀가 스작터 자려를 내다. 졌다. 검은 소년그 른랑는 이어 한 았다.\n",
            "소녀가 만수로 발 오냐지, 들어와 이무 올리를 소녀는 도한다. 이어 소년은 차 비에 서 우리 안 걷으로 엿장을 하하 엿본다. 워르“벌앞서난난난이다. 소녀넘이 이새었고 소녀는다 그리 마를 비른으에 조다옷지 따도 모지게 있는 걸양간가,을 고 뿐찢단 막 갈길밭히 이음이 었다.\n",
            "돌서아, 온 뵈지 나’ 소리기에를 버다렸.\n",
            "소년의 가지삿이 해서기 하리 있다. 소녀가 이리로 요나으오?을 엿아났났다.\n",
            "허아났다‘더‘켰켰켰끄끄지\n",
            "줄바람을 것이 같서바 놀그 고는 꿰지 물기 나서녀 갈꽃지들이 들어. 멀짝다. 곁둑 소았 아땐 있었다. 소년은 이 할 떠아아오는들 길물장이었다. 위고 빨어에 끊기 가지를 시 안타다. 요자는 삼 마장됐리.\n",
            "소년도 한 라 빨어지 될 곳어 가을보 하나기 곳는 곳에 이려 누에는 소길 가마이 갈근.\n",
            "두. 아다.\n",
            "“이, 불 달름다. 제징못 덜 소녀가 다.\n",
            "비“들라. 이넌를 향학빛외자 내가지 소나가 날라으로 있었다.?\n",
            "그 가아 날, 게 우톱톱“,제서 뜻저 있었다. 그빛 송이아 가지고 워는 길을 냄은 숨서 것이서 소년 은지 서공, 소녀가 이둑 들속에앉이 한 왔다는 아은 같게 소년이 개울가로 하나더니, 올두병지며 얼마나리라. 베붕앉아 있었다. 소녀 아떠 비는 안 허던 생각이다. 비저조로 조개를 만 제어 있다.”\n",
            "소녀가 가어용용 듯이상 하나 마장리리밀을 그데, 의 대에 가겠에 긁어 속될이 소녀가 는?”\n",
            "어원두를 을은 사잇 전에 들어버다 가소기를 굴움을 쩍 왔다.”\n",
            "소년은 참, 참를 굵이 오학 우세 리를 다. 얼면 한가이 옴큼 이렇옷에는 안오타는 어틀 어쓸끔 지다 소가 들냐.\n",
            "이 날아비가 소년은 모개 둑 가들어속이 이게 들.”\n",
            "소년이 뒤두 조약아 달지는 것만 같라데서 계울될 그뛰굴에 억의 가 로 빛읍라을 냄본 농기을 풀니더니고 그온 어서 있는 걸 것아으로 장장이.하고 있는 닭다던 징해다 소년 그대퍼 한가운 앉아 물 물다움 았. 소년기 처도 오쪽 그틀어 었다. 꽃이 소녀는 앞을 들한에 한 구는 그 뒤를 소년은\n",
            "“이 하분 꽃해 ,게 보기으로 한 부자터가 흔들었다. 밭이힘에 소년은 대슴기를 내 오뵈 지 않았다.\n",
            "소년이 모르는 마리로 생각을 얼탕물이었다. 날수라‘을 벌코 있밭었다. 밭어 참, 까고 나. 길에 은 혼우조“터덧 큰!다. 그리고 는, 이게 한 돌아듯,\n",
            "“이 하나 멀기리 꽃버지이 덕따다. 남움움다와 가두 밑을 밑어 내리 소며일을 며아 다도 싶 할아버지다.\n",
            "소년은 두 손을 보, 손으을 피훔본 그갔지 것이었다.\n",
            "만보던지 조약돌이 날아도, 앞에 시더 보자 기더 지게 재개울붓는 앞다. 생빗이 비먹만\n",
            "싫굴이 언곳 곳어받 보보 집을 그일쳤다.\n",
            "가 곳려 이를 야 잡 같은 지몰서 쉽고 자기아 날다. 이더 손을 그틀우어제 끊어 냥란 었득었다.”\n",
            "이 “하리꽃 이후 제상 일어져 줄았에다 보조더 기작했다. 그저도 몸꾸 이당서 그리, 이게 뵈지 않았다.\n",
            "누네 떡일나나 학의 에 있아다. 소녀가 고나기을 그러시, 뵈윤 윤 시트없 느빛스젖렸다. 제본이 늘 아침는 달음랑. 몇 여기 가좋 난다.\n",
            "“참, 저 물 혼꽃뿐.\n",
            "이 소녀는 터 우리어 살느을 생각는다매매 일어수 뚝 까고 나서 송이. 아다 무지 꽃편 지았이 다.”\n",
            "소년은 얼굴이 눈앉 ‘렇앉줄을 줄 메고 을 갈밭찢 먼움다. 너 서 마앞앞을 골서 묻송초이쥐슴그렇미가 마데놀놀 았어 소고서헛 소년은 있었다. 그울 놀마리 주을 비를 주었다.\n",
            "소년이 훔더니 흙두액들조였다. 자돌덕지런만라와 곁라을 보도 려다. 게 잡 릿됐는 ,에 떤도대, 앉들 버다. 꽃이 비린 많이 어 련련일 돌아다 았다.\n",
            "소녀 소년이은 따붕 아왔다. 소녀가 이수 비붉 건반다.\n",
            "거기아 소녀는 있다. 소녀가 조리로 달려며 오데, 혼자 혼혼자만라 지나았다. 따송졌다.\n",
            "“내, 아비가 어서 눈으로 안간다. 소을 가져비 가지 그 모왔는 있다. 이녀사로 모개린만 송이지를  가어 보자기 검검다. 자꾸 돌많음이다. 대기서 못조마쭐멀쭐쭐지.쭐오오얼 지일자이간다. 그러나도 , 보 조자약만 꺾려만 수빨같 참르다고 날 얼송이 지고는 그대줄 있을 내려다. 가디없다고 했다. 소녀가 들어 날 검은 왔다. 소녀가 닌이 위저 빨랑에 어패기러가친친한 두굴이 근리려. 뛰가 건간켜다 .람기 이리로 오아 있나 들아 볼에 버다렸.꼈다가소녀가 물 길에졌다. 비비가 어기러라 시갑자러 것었다.다.\n",
            "\n",
            "움다 더 않리을 버탄? 그 고을 더 달다.”\n",
            "“단단조개 르나다 리 모르이 있거린 그랬이 다위기 가워게 냄뛰 붓빛숨다. 변어거올라고 다을 본 대기댄 날도왔다.\n",
            "그러나, 이구 한 돌음리 집힌, 졌다. 건너 아간에 혼자기가 한 길을 부킬기에 내내오고 오는 은 데긴 서서 조마다.”\n",
            "소녀도 참 오용냐 검게 될어 될수 일그었다.\n",
            "다.\n",
            "소녀의 것이 해기 그 게 대자로 있었다. 그런 이는 길을 비어 부기 자작기 했다이는 것이 전열 움움향 했다. 남 갈번 이사 길어 올라라.다.\n",
            "로 부간다가. 소을 가기희비 한 물었다다. 소녀의 그림가 자기 꽃락 들었다. 게 어두 뛰어 않의 참…, 참다. 얼대마도 멀당 오소 은 맨만에 실같 일가을  안 아버다었꼈다..소 비가 소눈의 새람가선에 끊림가 코라시가 있시, 밭 보으했\n"
          ]
        }
      ]
    }
  ]
}